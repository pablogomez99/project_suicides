{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que vamos a hacer en nuestro notbook es el esquema, el esquema es la forma en la que queremos que nuestros datos aparezcan, escribimos el nombre de la columna y el tipo de dato que contiene, realizamos esto con todas las columnas y lo añadimos a la variable labels, y medante la función Struct type, crearemos el esuqema que mas adelante infereriremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ\n",
    "\n",
    "\n",
    "labels = [\n",
    "    ('country', typ.StringType()),\n",
    "    ('year', typ.IntegerType()),\n",
    "    ('sex', typ.StringType()),\n",
    "    ('age', typ.StringType()),\n",
    "    ('suicide_no', typ.IntegerType()),\n",
    "    ('population', typ.IntegerType()),\n",
    "    ('suicides/100k pop', typ.DoubleType()),\n",
    "    ('country-year', typ.StringType()),\n",
    "    ('HDI for year', typ.DoubleType()),\n",
    "    (' gdp_for_year ($) ', typ.StringType()),\n",
    "    ('gdp_per_capita ($)', typ.IntegerType()),\n",
    "    ('generation', typ.StringType())\n",
    "]\n",
    "\n",
    "mi_schema = typ.StructType([\n",
    "    typ.StructField(e[0], e[1], False) for e in labels\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creado el esquema, lo que vamos a hacer es importarnos el DataSet e inferir nuestro esquema, lo que conseguimos con esto es que todas las columnas se adopten el tipo de dato que nosotros hemos definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suicides = spark.read.csv('master.csv',header='true', inferSchema='false',schema = mi_schema,  sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la funcion withColumnRenamed, vamos a cambiar el nombre de ciertas variables ya que la informacion que nos dan con ese nombre nos parece confusa, en nustro caso, hemos cambiado las variables 'numero de suicidios por cada 100.000 habitantes', 'Indice de desarrollo humano por año', 'Producto interior bruto anual' y 'Producto interior bruto per capita'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suicides = suicides.withColumnRenamed('suicides/100k pop','Num_Suicides_100k')\n",
    "suicides = suicides.withColumnRenamed('HDI for year','IDH_Y')\n",
    "suicides = suicides.withColumnRenamed(' gdp_for_year ($) ','PIB_Y')\n",
    "suicides = suicides.withColumnRenamed('gdp_per_capita ($)','PIB_PerCapita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|        PIB_Y|\n",
      "+-------------+\n",
      "|2,156,624,900|\n",
      "|2,156,624,900|\n",
      "|2,156,624,900|\n",
      "|2,156,624,900|\n",
      "|2,156,624,900|\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suicides.select('PIB_Y').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando/Jugando con las funciones de pyspark (count , filter , distinct , collect ,etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql import functions as F\n",
    "#df_null=midata.select(*(F.sum(F.col(c).isNull().cast('Double')).alias(c) for c in midata.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandaDf = suicides.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandaDf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8551cb96b1c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpandaDf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pandaDf' is not defined"
     ]
    }
   ],
   "source": [
    "pandaDf['country'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                  0\n",
       "year                     0\n",
       "sex                      0\n",
       "age                      0\n",
       "suicide_no               0\n",
       "population               0\n",
       "Num_Suicides_100k        0\n",
       "country-year             0\n",
       "IDH_Y                19456\n",
       "PIB_Y                    0\n",
       "PIB_PerCapita            0\n",
       "generation               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandaDf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.699352983465133"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19456/len(pandaDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo que hay 19456 null, es decir un 70% de los datos, consideramos que lo mejor es eliminar o dejar de utilizar esa columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col4 {\n",
       "            background-color:  #a3c2fe;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col5 {\n",
       "            background-color:  #abc8fd;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col0 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col2 {\n",
       "            background-color:  #f3c8b2;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col3 {\n",
       "            background-color:  #aac7fd;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col4 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col5 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col0 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col1 {\n",
       "            background-color:  #f4c6af;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col2 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col3 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col4 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col5 {\n",
       "            background-color:  #536edd;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col1 {\n",
       "            background-color:  #a2c1ff;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col3 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col0 {\n",
       "            background-color:  #bcd2f7;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col1 {\n",
       "            background-color:  #6b8df0;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col2 {\n",
       "            background-color:  #5875e1;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col3 {\n",
       "            background-color:  #5b7ae5;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col4 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col5 {\n",
       "            background-color:  #f29072;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col0 {\n",
       "            background-color:  #b5cdfa;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col1 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col2 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col3 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col4 {\n",
       "            background-color:  #f4987a;\n",
       "            color:  #000000;\n",
       "        }    #T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col5 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >year</th>        <th class=\"col_heading level0 col1\" >suicide_no</th>        <th class=\"col_heading level0 col2\" >population</th>        <th class=\"col_heading level0 col3\" >Num_Suicides_100k</th>        <th class=\"col_heading level0 col4\" >IDH_Y</th>        <th class=\"col_heading level0 col5\" >PIB_PerCapita</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84level0_row0\" class=\"row_heading level0 row0\" >year</th>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col1\" class=\"data row0 col1\" >-0.004546</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col2\" class=\"data row0 col2\" >0.008850</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col3\" class=\"data row0 col3\" >-0.039037</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col4\" class=\"data row0 col4\" >0.366786</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row0_col5\" class=\"data row0 col5\" >0.339134</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84level0_row1\" class=\"row_heading level0 row1\" >suicide_no</th>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col0\" class=\"data row1 col0\" >-0.004546</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col2\" class=\"data row1 col2\" >0.616162</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col3\" class=\"data row1 col3\" >0.306604</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col4\" class=\"data row1 col4\" >0.151399</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row1_col5\" class=\"data row1 col5\" >0.061330</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84level0_row2\" class=\"row_heading level0 row2\" >population</th>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col0\" class=\"data row2 col0\" >0.008850</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col1\" class=\"data row2 col1\" >0.616162</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col3\" class=\"data row2 col3\" >0.008285</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col4\" class=\"data row2 col4\" >0.102943</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row2_col5\" class=\"data row2 col5\" >0.081510</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84level0_row3\" class=\"row_heading level0 row3\" >Num_Suicides_100k</th>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col0\" class=\"data row3 col0\" >-0.039037</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col1\" class=\"data row3 col1\" >0.306604</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col2\" class=\"data row3 col2\" >0.008285</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col4\" class=\"data row3 col4\" >0.074279</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row3_col5\" class=\"data row3 col5\" >0.001785</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84level0_row4\" class=\"row_heading level0 row4\" >IDH_Y</th>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col0\" class=\"data row4 col0\" >0.366786</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col1\" class=\"data row4 col1\" >0.151399</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col2\" class=\"data row4 col2\" >0.102943</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col3\" class=\"data row4 col3\" >0.074279</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row4_col5\" class=\"data row4 col5\" >0.771228</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84level0_row5\" class=\"row_heading level0 row5\" >PIB_PerCapita</th>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col0\" class=\"data row5 col0\" >0.339134</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col1\" class=\"data row5 col1\" >0.061330</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col2\" class=\"data row5 col2\" >0.081510</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col3\" class=\"data row5 col3\" >0.001785</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col4\" class=\"data row5 col4\" >0.771228</td>\n",
       "                        <td id=\"T_3de71d5e_9f6f_11ea_a419_6476ba93fb84row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1148c3310>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = pandaDf.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Num_Country1 = suicides.groupBy('country').count()\n",
    "Num_Country2 = suicides.select('country').distinct().count()\n",
    "Num_Country3 = Num_Country1.select('count').count()\n",
    "Num_Country2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Num_Country3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+\n",
      "|country|year|suicide_no|\n",
      "+-------+----+----------+\n",
      "|  Spain|1985|       305|\n",
      "|  Spain|1985|       624|\n",
      "|  Spain|1985|       131|\n",
      "|  Spain|1985|       497|\n",
      "|  Spain|1985|       219|\n",
      "+-------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SpainSuicides = suicides.select(\"country\",\"year\",\"suicide_no\").filter(\"country = 'Spain'\")\n",
    "SpainSuicides.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUE HACEN AQUI ESTOS TRANSFORMADORES??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "import pyspark.ml.feature as ft\n",
    "\n",
    "Variables_corr = ['year','suicide_no','population' , 'Num_Suicides_100k']\n",
    "\n",
    "assembler = ft.VectorAssembler( inputCols = Variables_corr, outputCol = \"features\")\n",
    "\n",
    "#datos1=suicides.select(Variables_corr).filter(\"Num_Suicides/100k is not null\")\n",
    "output = assembler.transform(suicides)\n",
    "r1 = Correlation.corr(output, \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30660445126778024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = suicides.corr( 'suicide_no','Num_Suicides_100k' )\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos la corelacion entre la variable objetivo 'Numero de suicidios por 100.000 habitantes' y la variables 'suicidios totales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature as ft\n",
    "\n",
    "featuresCreator = ft.VectorAssembler(\n",
    "    inputCols=[\n",
    "        col[0] \n",
    "        for col \n",
    "        in labels[2:]] , \n",
    "    outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Featureassenbler = ft.VectorAssembler(inputCols=[\"suicide_no\",\"population\", \"year\" ],outputCol=\"Independent Feature\" )\n",
    "output=Featureassenbler.transform(suicides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| Independent Feature|\n",
      "+--------------------+\n",
      "|[21.0,312900.0,19...|\n",
      "|[16.0,308000.0,19...|\n",
      "|[14.0,289700.0,19...|\n",
      "|[1.0,21800.0,1987.0]|\n",
      "|[9.0,274300.0,198...|\n",
      "|[1.0,35600.0,1987.0]|\n",
      "|[6.0,278800.0,198...|\n",
      "|[4.0,257200.0,198...|\n",
      "|[1.0,137500.0,198...|\n",
      "|[0.0,311000.0,198...|\n",
      "|[0.0,144600.0,198...|\n",
      "|[0.0,338200.0,198...|\n",
      "|[2.0,36400.0,1988.0]|\n",
      "|[17.0,319200.0,19...|\n",
      "|[1.0,22300.0,1988.0]|\n",
      "|[14.0,314100.0,19...|\n",
      "|[4.0,140200.0,198...|\n",
      "|[8.0,295600.0,198...|\n",
      "|[3.0,147500.0,198...|\n",
      "|[5.0,262400.0,198...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select(\"Independent Feature\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finalized_data = output.select(\"Independent Feature\",\"Num_Suicides_100k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "| Independent Feature|Num_Suicides_100k|\n",
      "+--------------------+-----------------+\n",
      "|[21.0,312900.0,19...|             6.71|\n",
      "|[16.0,308000.0,19...|             5.19|\n",
      "|[14.0,289700.0,19...|             4.83|\n",
      "|[1.0,21800.0,1987.0]|             4.59|\n",
      "|[9.0,274300.0,198...|             3.28|\n",
      "|[1.0,35600.0,1987.0]|             2.81|\n",
      "|[6.0,278800.0,198...|             2.15|\n",
      "|[4.0,257200.0,198...|             1.56|\n",
      "|[1.0,137500.0,198...|             0.73|\n",
      "|[0.0,311000.0,198...|              0.0|\n",
      "|[0.0,144600.0,198...|              0.0|\n",
      "|[0.0,338200.0,198...|              0.0|\n",
      "|[2.0,36400.0,1988.0]|             5.49|\n",
      "|[17.0,319200.0,19...|             5.33|\n",
      "|[1.0,22300.0,1988.0]|             4.48|\n",
      "|[14.0,314100.0,19...|             4.46|\n",
      "|[4.0,140200.0,198...|             2.85|\n",
      "|[8.0,295600.0,198...|             2.71|\n",
      "|[3.0,147500.0,198...|             2.03|\n",
      "|[5.0,262400.0,198...|             1.91|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=Finalized_data.randomSplit([0.80,0.20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es esto? regrasión lineal\n",
    "    # desde aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "regressor = LinearRegression(featuresCol='Independent Feature',labelCol='Num_Suicides_100k')\n",
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0105, -0.0, -0.0796])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+------------------+\n",
      "| Independent Feature|Num_Suicides_100k|        prediction|\n",
      "+--------------------+-----------------+------------------+\n",
      "|  [0.0,291.0,1994.0]|              0.0| 13.47766629776973|\n",
      "|  [0.0,302.0,1997.0]|              0.0| 13.23896635221675|\n",
      "|  [0.0,476.0,1986.0]|              0.0|14.113889539287783|\n",
      "|  [0.0,516.0,1998.0]|              0.0|13.159095541460744|\n",
      "|  [0.0,538.0,1987.0]|              0.0|14.034238535157243|\n",
      "|  [0.0,539.0,2001.0]|              0.0|12.920378242753117|\n",
      "|  [0.0,676.0,1989.0]|              0.0|13.874916281549133|\n",
      "|  [0.0,700.0,1986.0]|              0.0|14.113565613734409|\n",
      "|  [0.0,896.0,1993.0]|              0.0|13.556352755721292|\n",
      "|  [0.0,900.0,1990.0]|              0.0| 13.79503100983095|\n",
      "|  [0.0,949.0,1985.0]|              0.0|  14.1927668819404|\n",
      "|  [0.0,954.0,2003.0]|              0.0|12.760655420491986|\n",
      "|  [0.0,960.0,2014.0]|              0.0|11.885471936101311|\n",
      "|  [0.0,980.0,2001.0]|              0.0|12.919740514319955|\n",
      "| [0.0,1015.0,2010.0]|              0.0|12.203637785468601|\n",
      "| [0.0,1019.0,2008.0]|              0.0|12.362754693413422|\n",
      "| [0.0,1072.0,2013.0]|              0.0|11.964871319489475|\n",
      "| [0.0,1075.0,2002.0]|              0.0|12.840041789014151|\n",
      "| [0.0,1086.0,1993.0]|              0.0|13.556077997439417|\n",
      "| [0.0,1140.0,2001.0]|              0.0|12.919509138924695|\n",
      "| [0.0,1141.0,1988.0]|              0.0|13.953805192971544|\n",
      "| [0.0,1225.0,2006.0]|              0.0|12.521579489921749|\n",
      "| [0.0,1273.0,2004.0]|              0.0|12.680632769632837|\n",
      "| [0.0,1277.0,2009.0]|              0.0|12.282820254423712|\n",
      "| [0.0,1300.0,2004.0]|              0.0|12.680593725034896|\n",
      "| [0.0,1309.0,1999.0]|              0.0|13.078387440993168|\n",
      "| [0.0,1320.0,2004.0]|              0.0|12.680564803110485|\n",
      "| [0.0,1333.0,2008.0]|              0.0|12.362300619200226|\n",
      "| [0.0,1349.0,2005.0]|              0.0|12.600961520155238|\n",
      "| [0.0,1384.0,2004.0]|              0.0| 12.68047225295237|\n",
      "| [0.0,1386.0,1993.0]|              0.0| 13.55564416857331|\n",
      "| [0.0,1413.0,2006.0]|              0.0|12.521307623832314|\n",
      "| [0.0,1426.0,2005.0]|              0.0|12.600850170746298|\n",
      "| [0.0,1437.0,1994.0]|              0.0| 13.47600907150121|\n",
      "| [0.0,1490.0,1989.0]|              0.0|13.873739159225778|\n",
      "| [0.0,1500.0,1985.0]|              0.0|14.191970082922978|\n",
      "| [0.0,1500.0,1987.0]|              0.0|14.032847390593275|\n",
      "| [0.0,1539.0,1999.0]|              0.0|  13.0780548388625|\n",
      "| [0.0,1547.0,2002.0]|              0.0|12.839359231598166|\n",
      "| [0.0,1600.0,1987.0]|              0.0|14.032702780971249|\n",
      "| [0.0,1624.0,2007.0]|              0.0|12.441441151364955|\n",
      "| [0.0,1654.0,2007.0]|              0.0|12.441397768478339|\n",
      "| [0.0,1681.0,2009.0]|              0.0|12.282236031550696|\n",
      "| [0.0,1686.0,2014.0]|              0.0|11.884422070245336|\n",
      "| [0.0,1707.0,2002.0]|              0.0|12.839127856202907|\n",
      "| [0.0,1724.0,2015.0]|              0.0|11.804805772424118|\n",
      "| [0.0,1759.0,2005.0]|              0.0|12.600368620704927|\n",
      "| [0.0,1779.0,2009.0]|              0.0| 12.28209431412111|\n",
      "| [0.0,1785.0,1993.0]|              0.0| 13.55506717618141|\n",
      "| [0.0,1807.0,2011.0]|              0.0|12.122931131097232|\n",
      "| [0.0,1810.0,1998.0]|              0.0| 13.15722429295161|\n",
      "| [0.0,1820.0,2006.0]|              0.0|12.520719062670622|\n",
      "| [0.0,1825.0,2007.0]|              0.0|12.441150486024668|\n",
      "| [0.0,1850.0,2000.0]|              0.0|12.998043756773114|\n",
      "| [0.0,1926.0,2009.0]|              0.0|12.281881737976704|\n",
      "| [0.0,2033.0,2005.0]|              0.0|12.599972390340554|\n",
      "| [0.0,2219.0,2013.0]|              0.0|11.963212647124749|\n",
      "| [0.0,2224.0,2001.0]|              0.0| 12.91794157062185|\n",
      "| [0.0,2227.0,2009.0]|              0.0| 12.28144646301439|\n",
      "| [0.0,2227.0,2016.0]|              0.0|11.724517039860444|\n",
      "| [0.0,2250.0,1997.0]|              0.0| 13.23614935677955|\n",
      "| [0.0,2251.0,2009.0]|              0.0|12.281411756705097|\n",
      "| [0.0,2313.0,2014.0]|              0.0|11.883515367915209|\n",
      "| [0.0,2327.0,2002.0]|              0.0| 12.83823127654631|\n",
      "| [0.0,2370.0,2011.0]|              0.0|12.122116978925192|\n",
      "| [0.0,2400.0,1990.0]|              0.0|13.792861865500441|\n",
      "| [0.0,2400.0,1991.0]|              0.0|13.713300519335604|\n",
      "| [0.0,2400.0,1992.0]|              0.0|13.633739173170738|\n",
      "| [0.0,2407.0,1996.0]|              0.0|13.315483665837775|\n",
      "| [0.0,2418.0,2003.0]|              0.0|12.758538335625417|\n",
      "| [0.0,2460.0,1992.0]|              0.0|13.633652407397506|\n",
      "| [0.0,2500.0,1992.0]|              0.0|13.633594563548712|\n",
      "| [0.0,2500.0,1994.0]|              0.0| 13.47447187121901|\n",
      "| [0.0,2577.0,2001.0]|              0.0|12.917431098656095|\n",
      "| [0.0,2590.0,2000.0]|              0.0|12.996973645570051|\n",
      "| [0.0,2600.0,1990.0]|              0.0| 13.79257264625636|\n",
      "| [0.0,2600.0,1995.0]|              0.0|13.394765915432117|\n",
      "| [0.0,2617.0,2005.0]|              0.0|12.599127870147868|\n",
      "| [0.0,2700.0,1997.0]|              0.0|13.235498613480388|\n",
      "| [0.0,2744.0,2006.0]|              0.0|12.519382869763035|\n",
      "| [0.0,2813.0,1988.0]|              0.0| 13.95138732009113|\n",
      "| [0.0,2830.0,2010.0]|              0.0| 12.20101312082869|\n",
      "| [0.0,2878.0,1994.0]|              0.0|13.473925246847699|\n",
      "| [0.0,2900.0,1985.0]|              0.0|14.189945548214496|\n",
      "| [0.0,3018.0,2009.0]|              0.0|12.280302600904093|\n",
      "| [0.0,3048.0,2010.0]|              0.0|12.200697871852668|\n",
      "| [0.0,3072.0,2005.0]|              0.0|12.598469896367618|\n",
      "| [0.0,3082.0,2014.0]|              0.0|11.882403319921764|\n",
      "| [0.0,3117.0,2004.0]|              0.0|12.677966168202545|\n",
      "| [0.0,3228.0,2001.0]|              0.0|12.916489690016647|\n",
      "| [0.0,3250.0,2016.0]|              0.0|11.723037683427037|\n",
      "| [0.0,3276.0,1999.0]|              0.0|13.075542969727763|\n",
      "| [0.0,3300.0,1991.0]|              0.0|13.711999032737282|\n",
      "| [0.0,3400.0,1985.0]|              0.0|14.189222500104336|\n",
      "| [0.0,3453.0,2004.0]|              0.0|12.677480279872498|\n",
      "| [0.0,3461.0,2002.0]|              0.0|12.836591403432436|\n",
      "| [0.0,3525.0,2003.0]|              0.0|12.756937507109512|\n",
      "| [0.0,3696.0,1989.0]|              0.0|13.870549070963705|\n",
      "| [0.0,3715.0,1994.0]|              0.0|13.472714864311286|\n",
      "| [0.0,3764.0,1986.0]|              0.0|14.109134774915304|\n",
      "| [0.0,3854.0,1998.0]|              0.0|13.154268472277266|\n",
      "| [0.0,3936.0,2011.0]|              0.0|12.119852392244127|\n",
      "| [0.0,3968.0,1999.0]|              0.0|13.074542271143287|\n",
      "| [0.0,4000.0,1988.0]|              0.0| 13.94967080387761|\n",
      "| [0.0,4017.0,2012.0]|              0.0| 12.04017391228544|\n",
      "| [0.0,4051.0,1999.0]|              0.0|13.074422245157024|\n",
      "| [0.0,4054.0,2003.0]|              0.0|12.756172522208942|\n",
      "| [0.0,4063.0,2005.0]|              0.0|12.597036815013269|\n",
      "| [0.0,4091.0,2009.0]|              0.0|12.278750939659687|\n",
      "| [0.0,4100.0,1985.0]|              0.0|14.188210232750095|\n",
      "| [0.0,4112.0,1993.0]|              0.0|13.551702110276665|\n",
      "| [0.0,4117.0,2000.0]|              0.0|12.994765456641602|\n",
      "| [0.0,4120.0,2004.0]|              0.0|12.676515733693549|\n",
      "| [0.0,4158.0,2008.0]|              0.0| 12.35821539737779|\n",
      "| [0.0,4163.0,2014.0]|              0.0|11.880840089907565|\n",
      "| [0.0,4245.0,2007.0]|              0.0|12.437650933171454|\n",
      "| [0.0,4289.0,2010.0]|              0.0| 12.19890326644321|\n",
      "| [0.0,4324.0,2005.0]|              0.0|12.596659383899748|\n",
      "| [0.0,4327.0,2003.0]|              0.0|12.755777737940804|\n",
      "| [0.0,4389.0,2005.0]|              0.0|12.596565387645427|\n",
      "| [0.0,4398.0,2008.0]|              0.0|12.357868334284916|\n",
      "| [0.0,4400.0,2007.0]|              0.0|12.437426788257312|\n",
      "| [0.0,4414.0,1997.0]|              0.0|13.233020004558739|\n",
      "| [0.0,4500.0,1986.0]|              0.0|14.108070448097124|\n",
      "| [0.0,4500.0,1988.0]|              0.0| 13.94894775576742|\n",
      "| [0.0,4529.0,1998.0]|              0.0|13.153292357328525|\n",
      "| [0.0,4575.0,2008.0]|              0.0|12.357612375253893|\n",
      "| [0.0,4580.0,2009.0]|              0.0| 12.27804379860794|\n",
      "| [0.0,4589.0,2005.0]|              0.0|12.596276168401374|\n",
      "| [0.0,4700.0,1985.0]|              0.0|14.187342575017908|\n",
      "| [0.0,4700.0,1987.0]|              0.0|14.028219882688205|\n",
      "| [0.0,4715.0,2010.0]|              0.0|12.198287229453342|\n",
      "| [0.0,4742.0,2011.0]|              0.0|12.118686838690536|\n",
      "| [0.0,4788.0,2009.0]|              0.0|12.277743010594094|\n",
      "| [0.0,4793.0,2005.0]|              0.0|12.595981164772411|\n",
      "| [0.0,4800.0,1985.0]|              0.0|14.187197965395882|\n",
      "| [0.0,4852.0,2007.0]|              0.0| 12.43677315276571|\n",
      "| [0.0,4900.0,1990.0]|              0.0|13.789246624949584|\n",
      "| [0.0,4955.0,1994.0]|              0.0|13.470921704998062|\n",
      "| [0.0,4994.0,2012.0]|              0.0|12.038761076278178|\n",
      "| [0.0,5000.0,1989.0]|              0.0|13.868663361492395|\n",
      "| [0.0,5000.0,1993.0]|              0.0|13.550417976833018|\n",
      "| [0.0,5046.0,2007.0]|              0.0|12.436492610098952|\n",
      "| [0.0,5052.0,2006.0]|              0.0|12.516045279686494|\n",
      "| [0.0,5100.0,1995.0]|              0.0|13.391150674881288|\n",
      "| [0.0,5178.0,2008.0]|              0.0|12.356740379233031|\n",
      "| [0.0,5226.0,1998.0]|              0.0| 13.15228442826296|\n",
      "| [0.0,5229.0,2002.0]|              0.0|12.834034705314878|\n",
      "| [0.0,5238.0,2013.0]|              0.0|11.958846882635555|\n",
      "| [0.0,5254.0,1985.0]|              0.0|14.186541437711838|\n",
      "| [0.0,5299.0,2007.0]|              0.0|12.436126747755225|\n",
      "| [0.0,5300.0,1994.0]|              0.0|13.470422801802044|\n",
      "| [0.0,5346.0,1996.0]|              0.0|13.311233589046225|\n",
      "| [0.0,5381.0,2010.0]|              0.0|  12.1973241293706|\n",
      "| [0.0,5474.0,2011.0]|              0.0|12.117628296257266|\n",
      "| [0.0,5500.0,1986.0]|              0.0|14.106624351876803|\n",
      "| [0.0,5544.0,2011.0]|              0.0|12.117527069521827|\n",
      "| [0.0,5558.0,2009.0]|              0.0|12.276629516504443|\n",
      "| [0.0,5563.0,1999.0]|              0.0|13.072235747671868|\n",
      "| [0.0,5600.0,1993.0]|              0.0|13.549550319100831|\n",
      "| [0.0,5683.0,2005.0]|              0.0|12.594694139136323|\n",
      "| [0.0,5692.0,2001.0]|              0.0| 12.91292650892973|\n",
      "| [0.0,5712.0,2001.0]|              0.0|12.912897587005318|\n",
      "| [0.0,5815.0,1999.0]|              0.0|13.071871331424347|\n",
      "| [0.0,5862.0,1989.0]|              0.0|13.867416826550453|\n",
      "| [0.0,5879.0,2000.0]|              0.0|12.992217435101367|\n",
      "| [0.0,5900.0,1995.0]|              0.0| 13.38999379790502|\n",
      "| [0.0,6051.0,2005.0]|              0.0|12.594161975727218|\n",
      "| [0.0,6059.0,1987.0]|              0.0|14.026254637924751|\n",
      "| [0.0,6093.0,2016.0]|              0.0|11.718926431872632|\n",
      "| [0.0,6100.0,1985.0]|              0.0|14.185318040309426|\n",
      "| [0.0,6163.0,1995.0]|              0.0| 13.38961347459906|\n",
      "| [0.0,6229.0,2014.0]|              0.0|11.877852455116368|\n",
      "| [0.0,6245.0,2014.0]|              0.0| 11.87782931757684|\n",
      "| [0.0,6274.0,2008.0]|              0.0|12.355155457775567|\n",
      "| [0.0,6344.0,1985.0]|              0.0|14.184965192831669|\n",
      "| [0.0,6348.0,2007.0]|              0.0|12.434609792820083|\n",
      "| [0.0,6401.0,1991.0]|              0.0|13.707514688358032|\n",
      "| [0.0,6442.0,2000.0]|              0.0|12.991403282929326|\n",
      "| [0.0,6444.0,2013.0]|              0.0| 11.95710289059383|\n",
      "| [0.0,6481.0,1999.0]|              0.0|13.070908231341605|\n",
      "| [0.0,6497.0,1992.0]|              0.0|13.627814516956022|\n",
      "| [0.0,6498.0,2010.0]|              0.0| 12.19570883989249|\n",
      "| [0.0,6499.0,1987.0]|              0.0|14.025618355587824|\n",
      "| [0.0,6499.0,2013.0]|              0.0|11.957023355301715|\n",
      "| [0.0,6519.0,2006.0]|              0.0|12.513923856531278|\n",
      "| [0.0,6532.0,2003.0]|              0.0|12.752589095774937|\n",
      "| [0.0,6548.0,2007.0]|              0.0| 12.43432057357603|\n",
      "| [0.0,6556.0,2004.0]|              0.0|12.672993043300806|\n",
      "| [0.0,6565.0,1994.0]|              0.0|13.468593490083322|\n",
      "| [0.0,6576.0,2005.0]|              0.0|12.593402775211558|\n",
      "| [0.0,6600.0,1993.0]|              0.0|13.548104222880482|\n",
      "| [0.0,6600.0,2009.0]|              0.0| 12.27512268424286|\n",
      "| [0.0,6616.0,2000.0]|              0.0| 12.99115166218698|\n",
      "| [0.0,6621.0,1989.0]|              0.0|13.866319239519243|\n",
      "| [0.0,6623.0,1987.0]|              0.0|14.025439039656504|\n",
      "| [0.0,6724.0,2012.0]|              0.0|   12.036259329817|\n",
      "| [0.0,6734.0,2003.0]|              0.0|12.752296984338443|\n",
      "| [0.0,6827.0,1986.0]|              0.0|14.104705382192407|\n",
      "| [0.0,6827.0,1990.0]|              0.0|   13.786459997533|\n",
      "| [0.0,6831.0,1992.0]|              0.0|13.627331520818416|\n",
      "| [0.0,6845.0,1993.0]|              0.0|13.547749929306491|\n",
      "| [0.0,6887.0,2005.0]|              0.0|12.592953039287039|\n",
      "| [0.0,6907.0,1986.0]|              0.0|14.104589694494791|\n",
      "| [0.0,6915.0,1993.0]|              0.0|13.547648702571081|\n",
      "| [0.0,6928.0,2006.0]|              0.0|12.513332403177145|\n",
      "| [0.0,6961.0,2005.0]|              0.0|12.592846028166718|\n",
      "| [0.0,6966.0,1996.0]|              0.0|13.308890913169279|\n",
      "| [0.0,6985.0,1994.0]|              0.0|13.467986129670777|\n",
      "| [0.0,6988.0,2010.0]|              0.0|12.195000252744535|\n",
      "| [0.0,7000.0,1987.0]|              0.0|14.024893861381429|\n",
      "| [0.0,7048.0,1997.0]|              0.0|13.229210987114357|\n",
      "| [0.0,7059.0,2015.0]|              0.0|11.797090849088619|\n",
      "| [0.0,7072.0,1995.0]|              0.0|13.388298973134766|\n",
      "| [0.0,7124.0,1985.0]|              0.0|14.183837237779812|\n",
      "| [0.0,7148.0,2010.0]|              0.0|12.194768877349276|\n",
      "| [0.0,7154.0,2013.0]|              0.0|11.956076162277384|\n",
      "| [0.0,7174.0,2001.0]|              0.0| 12.91078339433119|\n",
      "| [0.0,7178.0,2009.0]|              0.0|12.274286840627497|\n",
      "| [0.0,7211.0,2012.0]|              0.0|12.035555080957693|\n",
      "| [0.0,7233.0,2002.0]|              0.0|12.831136728489327|\n",
      "| [0.0,7263.0,2009.0]|              0.0|12.274163922448764|\n",
      "| [0.0,7290.0,2001.0]|              0.0|12.910615647169635|\n",
      "| [0.0,7300.0,1991.0]|              0.0|13.706214647855944|\n",
      "| [0.0,7316.0,2006.0]|              0.0|12.512771317843658|\n",
      "| [0.0,7333.0,1995.0]|              0.0|13.387921542021274|\n",
      "| [0.0,7339.0,1985.0]|              0.0|14.183526327092437|\n",
      "| [0.0,7357.0,1994.0]|              0.0|13.467448181876819|\n",
      "| [0.0,7376.0,1997.0]|              0.0|13.228736667554102|\n",
      "| [0.0,7400.0,1986.0]|              0.0| 14.10387676905816|\n",
      "| [0.0,7400.0,1987.0]|              0.0|14.024315422893295|\n",
      "| [0.0,7403.0,1994.0]|              0.0|13.467381661450673|\n",
      "| [0.0,7421.0,1992.0]|              0.0|13.626478324048435|\n",
      "| [0.0,7428.0,1995.0]|              0.0|13.387784162880337|\n",
      "| [0.0,7476.0,2008.0]|              0.0|12.353417250118696|\n",
      "| [0.0,7479.0,2003.0]|              0.0|12.751219642654291|\n",
      "| [0.0,7481.0,2008.0]|              0.0|12.353410019637607|\n",
      "| [0.0,7500.0,1986.0]|              0.0|14.103732159436134|\n",
      "| [0.0,7507.0,2006.0]|              0.0|12.512495113465576|\n",
      "| [0.0,7531.0,2004.0]|              0.0|12.671583099485957|\n",
      "| [0.0,7550.0,2003.0]|              0.0|12.751116969822647|\n",
      "| [0.0,7578.0,2014.0]|              0.0| 11.87590167131512|\n",
      "| [0.0,7610.0,2005.0]|              0.0|12.591907511719711|\n",
      "| [0.0,7668.0,1986.0]|              0.0| 14.10348921527111|\n",
      "| [0.0,7704.0,2014.0]|              0.0| 11.87571946319136|\n",
      "| [0.0,7772.0,1997.0]|              0.0| 13.22816401345085|\n",
      "| [0.0,7780.0,2005.0]|              0.0|12.591661675362275|\n",
      "| [0.0,7805.0,1999.0]|              0.0|13.068993599945856|\n",
      "| [0.0,7809.0,1995.0]|              0.0|13.387233200220379|\n",
      "| [0.0,7832.0,2001.0]|              0.0|12.909831863018212|\n",
      "| [0.0,7893.0,2012.0]|              0.0|12.034568843335421|\n",
      "| [0.0,7900.0,1986.0]|              0.0|   14.103153720948|\n",
      "| [0.0,7901.0,2002.0]|              0.0|12.830170736214143|\n",
      "| [0.0,7902.0,2006.0]|              0.0| 12.51192390545856|\n",
      "| [0.0,7908.0,1994.0]|              0.0|13.466651382859425|\n",
      "| [0.0,7973.0,2000.0]|              0.0|12.989189309615995|\n",
      "| [0.0,7976.0,2008.0]|              0.0|12.352694202008536|\n",
      "| [0.0,8000.0,1989.0]|              0.0|13.864325072831377|\n",
      "| [0.0,8022.0,2005.0]|              0.0| 12.59131172007693|\n",
      "| [0.0,8038.0,2008.0]|              0.0| 12.35260454404289|\n",
      "| [0.0,8075.0,2000.0]|              0.0|12.989041807801499|\n",
      "| [0.0,8078.0,2010.0]|              0.0|12.193424007864365|\n",
      "| [0.0,8087.0,1995.0]|              0.0|13.386831185471124|\n",
      "| [0.0,8108.0,2008.0]|              0.0|12.352503317307452|\n",
      "| [0.0,8117.0,2001.0]|              0.0|12.909419725595427|\n",
      "| [0.0,8262.0,2006.0]|              0.0|12.511403310819219|\n",
      "| [0.0,8268.0,2015.0]|              0.0|11.795342518758218|\n",
      "| [0.0,8330.0,2000.0]|              0.0| 12.98867305326533|\n",
      "| [0.0,8332.0,1998.0]|              0.0|13.147792853402592|\n",
      "| [0.0,8335.0,2014.0]|              0.0|11.874806976476322|\n",
      "| [0.0,8353.0,2005.0]|              0.0|   12.590833062228|\n",
      "| [0.0,8358.0,2005.0]|              0.0|12.590825831746912|\n",
      "| [0.0,8400.0,1990.0]|              0.0|13.784185288178406|\n",
      "| [0.0,8405.0,2013.0]|              0.0|11.954267095905749|\n",
      "| [0.0,8439.0,2000.0]|              0.0|12.988515428777305|\n",
      "| [0.0,8485.0,2006.0]|              0.0| 12.51108083136208|\n",
      "| [0.0,8500.0,1991.0]|              0.0|13.704479332391543|\n",
      "| [0.0,8552.0,2001.0]|              0.0| 12.90879067373956|\n",
      "| [0.0,8555.0,2007.0]|              0.0|12.431418258461804|\n",
      "| [0.0,8619.0,2015.0]|              0.0|11.794834938984877|\n",
      "| [0.0,8625.0,2000.0]|              0.0|12.988246454880311|\n",
      "| [0.0,8643.0,2009.0]|              0.0|12.272168309664721|\n",
      "| [0.0,8653.0,2000.0]|              0.0|12.988205964186164|\n",
      "| [0.0,8694.0,2013.0]|              0.0|11.953849174098053|\n",
      "| [0.0,8700.0,1985.0]|              0.0|14.181558190136542|\n",
      "| [0.0,8791.0,1995.0]|              0.0|13.385813133732029|\n",
      "| [0.0,8932.0,1991.0]|              0.0|13.703854618824352|\n",
      "| [0.0,8935.0,1992.0]|              0.0|13.624288934370838|\n",
      "| [0.0,9000.0,1995.0]|              0.0|13.385510899621977|\n",
      "| [0.0,9003.0,2002.0]|              0.0|12.828577138179327|\n",
      "| [0.0,9006.0,2010.0]|              0.0|12.192082030571896|\n",
      "| [0.0,9144.0,2014.0]|              0.0|11.873637084634083|\n",
      "| [0.0,9213.0,1991.0]|              0.0|13.703448265786449|\n",
      "| [0.0,9266.0,2015.0]|              0.0| 11.79389931473034|\n",
      "| [0.0,9341.0,2008.0]|              0.0|12.350720280667787|\n",
      "| [0.0,9347.0,2010.0]|              0.0| 12.19158891176076|\n",
      "| [0.0,9500.0,1985.0]|              0.0|14.180401313160274|\n",
      "| [0.0,9542.0,2008.0]|              0.0|  12.3504296153275|\n",
      "| [0.0,9543.0,2016.0]|              0.0|11.713937399912453|\n",
      "| [0.0,9566.0,2005.0]|              0.0|12.589078947512746|\n",
      "| [0.0,9580.0,2008.0]|              0.0|12.350374663671118|\n",
      "| [0.0,9615.0,1998.0]|              0.0|  13.1459375119519|\n",
      "| [0.0,9636.0,2014.0]|              0.0| 11.87292560529366|\n",
      "| [0.0,9683.0,2008.0]|              0.0|12.350225715760416|\n",
      "| [0.0,9700.0,1986.0]|              0.0|14.100550747751385|\n",
      "| [0.0,9700.0,1994.0]|              0.0|13.464059978432573|\n",
      "| [0.0,9748.0,2013.0]|              0.0|11.952324988681823|\n",
      "| [0.0,9786.0,2009.0]|              0.0|12.270515421684877|\n",
      "| [0.0,9888.0,2014.0]|              0.0|11.872561189046138|\n",
      "| [0.0,9927.0,2006.0]|              0.0|12.508995560612362|\n",
      "| [0.0,9944.0,2009.0]|              0.0|12.270286938482059|\n",
      "| [0.0,9952.0,2009.0]|              0.0|12.270275369712294|\n",
      "|[0.0,10010.0,2005.0]|              0.0|12.588436880790908|\n",
      "|[0.0,10127.0,2015.0]|              0.0|11.792654225884633|\n",
      "|[0.0,10129.0,2006.0]|              0.0|12.508703449175869|\n",
      "|[0.0,10175.0,2008.0]|              0.0| 12.34951423642002|\n",
      "|[0.0,10206.0,2014.0]|              0.0| 11.87210133044809|\n",
      "|[0.0,10217.0,2009.0]|              0.0|12.269892154213892|\n",
      "|[0.0,10271.0,2016.0]|              0.0|11.712884641864065|\n",
      "|[0.0,10277.0,2007.0]|              0.0| 12.42892808077039|\n",
      "|[0.0,10331.0,2004.0]|              0.0|12.667534030069021|\n",
      "|[0.0,10344.0,2008.0]|              0.0| 12.34926984615879|\n",
      "|[0.0,10435.0,2008.0]|              0.0|12.349138251402735|\n",
      "|[0.0,10459.0,2004.0]|              0.0| 12.66734892975282|\n",
      "|[0.0,10500.0,1990.0]|              0.0|13.781148486115711|\n",
      "|[0.0,10509.0,2010.0]|              0.0|12.189908547952712|\n",
      "|[0.0,10526.0,2007.0]|              0.0|12.428568002811517|\n",
      "|[0.0,10571.0,2013.0]|              0.0|11.951134851492498|\n",
      "|[0.0,10604.0,2002.0]|              0.0|12.826261938130585|\n",
      "|[0.0,10640.0,2004.0]|              0.0|12.667087186336943|\n",
      "|[0.0,10657.0,1989.0]|              0.0|13.860482795173937|\n",
      "|[0.0,10730.0,2012.0]|              0.0|12.030466268358339|\n",
      "|[0.0,10749.0,2004.0]|              0.0|12.666929561848917|\n",
      "|[0.0,10775.0,1997.0]|              0.0|13.223821386501157|\n",
      "|[0.0,10814.0,2010.0]|              0.0|12.189467488605516|\n",
      "|[0.0,10875.0,2011.0]|              0.0| 12.10981793057121|\n",
      "|[0.0,10910.0,2006.0]|              0.0|12.507574048027777|\n",
      "|[0.0,10981.0,2014.0]|              0.0|11.870980605877321|\n",
      "|[0.0,11045.0,1989.0]|              0.0| 13.85992170984045|\n",
      "|[0.0,11093.0,1999.0]|              0.0|13.064238835573406|\n",
      "|[0.0,11110.0,2003.0]|              0.0|12.745968867278236|\n",
      "|[0.0,11126.0,1999.0]|              0.0|13.064191114398113|\n",
      "|[0.0,11222.0,2016.0]|              0.0|11.711509404358509|\n",
      "|[0.0,11268.0,2016.0]|              0.0|11.711442883932392|\n",
      "|[0.0,11369.0,2014.0]|              0.0|11.870419520543834|\n",
      "|[0.0,11413.0,1987.0]|              0.0|14.018512238761076|\n",
      "|[0.0,11526.0,1989.0]|              0.0|13.859226137558466|\n",
      "|[0.0,11584.0,1985.0]|              0.0|14.177387648637108|\n",
      "|[0.0,11738.0,1998.0]|              0.0|13.142867449676118|\n",
      "|[0.0,11760.0,2002.0]|              0.0| 12.82459025089986|\n",
      "|[0.0,11805.0,1989.0]|              0.0|13.858822676713004|\n",
      "|[0.0,11868.0,2002.0]|              0.0|12.824434072508069|\n",
      "|[0.0,11874.0,2003.0]|              0.0|12.744864049765908|\n",
      "|[0.0,11907.0,2013.0]|              0.0| 11.94920286694213|\n",
      "|[0.0,11910.0,2002.0]|              0.0|12.824373336466806|\n",
      "|[0.0,12042.0,2006.0]|              0.0|12.505937067106345|\n",
      "|[0.0,12100.0,1985.0]|              0.0| 14.17664146298742|\n",
      "|[0.0,12185.0,2008.0]|              0.0|12.346607583017146|\n",
      "|[0.0,12189.0,1996.0]|              0.0|13.301337952610453|\n",
      "|[0.0,12200.0,1993.0]|              0.0|13.540006084046581|\n",
      "|[0.0,12360.0,1996.0]|              0.0|13.301090670156782|\n",
      "|[0.0,12500.0,1986.0]|              0.0|14.096501678334448|\n",
      "|[0.0,12507.0,2011.0]|              0.0|12.107457901539618|\n",
      "|[0.0,12812.0,2003.0]|              0.0|12.743507611511234|\n",
      "|[0.0,12814.0,2010.0]|              0.0|12.186575296164847|\n",
      "|[0.0,12978.0,2009.0]|              0.0|12.265899482549543|\n",
      "|[0.0,12981.0,2000.0]|              0.0|12.981947259744544|\n",
      "|[0.0,13158.0,2004.0]|              0.0|12.663445916054144|\n",
      "|[0.0,13200.0,1990.0]|              0.0|13.777244026320801|\n",
      "|[0.0,13293.0,1989.0]|              0.0|13.856670885537142|\n",
      "|[0.0,13364.0,2005.0]|              0.0|12.583586674067902|\n",
      "|[0.0,13370.0,2015.0]|              0.0|11.787964535842065|\n",
      "|[0.0,13374.0,1995.0]|              0.0|13.379185674754211|\n",
      "|[0.0,13500.0,1990.0]|              0.0|13.776810197454694|\n",
      "|[0.0,13501.0,1993.0]|              0.0|13.538124712863947|\n",
      "|[0.0,13551.0,1996.0]|              0.0|13.299368369558351|\n",
      "|[0.0,13684.0,2005.0]|              0.0|12.583123923277384|\n",
      "|[0.0,13949.0,2011.0]|              0.0|12.105372630789901|\n",
      "|[0.0,13973.0,1996.0]|              0.0|13.298758116953366|\n",
      "|[0.0,14124.0,2013.0]|              0.0|11.945996871621645|\n",
      "|[0.0,14156.0,1991.0]|              0.0| 13.69630021216932|\n",
      "|[0.0,14183.0,1997.0]|              0.0| 13.21889309058227|\n",
      "|[0.0,14278.0,2008.0]|              0.0| 12.34358090362798|\n",
      "|[0.0,14696.0,2003.0]|              0.0| 12.74078316623212|\n",
      "|[0.0,14823.0,2015.0]|              0.0|11.785863358033907|\n",
      "|[0.0,15000.0,1987.0]|              0.0|14.013325091618725|\n",
      "|[0.0,15127.0,2000.0]|              0.0|12.978843937255704|\n",
      "|[0.0,15300.0,1987.0]|              0.0|14.012891262752618|\n",
      "|[0.0,15351.0,2004.0]|              0.0|12.660274627042924|\n",
      "|[0.0,15542.0,1999.0]|              0.0|13.057805153489113|\n",
      "|[0.0,15545.0,2010.0]|              0.0|12.182626007387114|\n",
      "|[0.0,15700.0,1988.0]|              0.0|13.932751478099647|\n",
      "|[0.0,15921.0,1986.0]|              0.0| 14.09155458316468|\n",
      "|[0.0,16001.0,2012.0]|              0.0|12.022843895180927|\n",
      "|[0.0,16100.0,2004.0]|              0.0| 12.65919150097389|\n",
      "|[0.0,16343.0,2003.0]|              0.0|12.738401445757233|\n",
      "|[0.0,16444.0,1992.0]|              0.0|13.613430197852324|\n",
      "|[0.0,16468.0,1991.0]|              0.0|13.692956837707897|\n",
      "|[0.0,16600.0,1987.0]|              0.0| 14.01101133766619|\n",
      "|[0.0,16645.0,2004.0]|              0.0| 12.65840337853382|\n",
      "|[0.0,16844.0,1997.0]|              0.0|13.215045028539947|\n",
      "|[0.0,17000.0,1990.0]|              0.0|13.771748860683516|\n",
      "|[0.0,17111.0,2002.0]|              0.0|12.816852190024832|\n",
      "|[0.0,17304.0,2001.0]|              0.0|12.896134439619175|\n",
      "|[0.0,17444.0,2000.0]|              0.0|12.975493332313164|\n",
      "|[0.0,17621.0,2003.0]|              0.0| 12.73655333478763|\n",
      "|[0.0,17769.0,2004.0]|              0.0|12.656777966382151|\n",
      "|[0.0,18062.0,2003.0]|              0.0|12.735915606354467|\n",
      "|[0.0,18117.0,1999.0]|              0.0|13.054081455721757|\n",
      "|[0.0,18523.0,2012.0]|              0.0|12.019196840513246|\n",
      "|[0.0,18579.0,2012.0]|              0.0|12.019115859124895|\n",
      "|[0.0,18660.0,2011.0]|              0.0|12.098560071495882|\n",
      "|[0.0,18772.0,2007.0]|              0.0|12.416643493378615|\n",
      "|[0.0,18856.0,2005.0]|              0.0| 12.57564471362582|\n",
      "|[0.0,19000.0,1985.0]|              0.0| 14.16666339906709|\n",
      "|[0.0,19044.0,2009.0]|              0.0| 12.25712746287698|\n",
      "|[0.0,19076.0,2004.0]|              0.0|12.654887918622165|\n",
      "|[0.0,19271.0,1989.0]|              0.0|13.848026122331959|\n",
      "|[0.0,19279.0,2008.0]|              0.0| 12.33634897643006|\n",
      "|[0.0,19300.0,1987.0]|              0.0| 14.00710687787128|\n",
      "|[0.0,19356.0,2006.0]|              0.0|12.495360319350794|\n",
      "|[0.0,19402.0,2012.0]|              0.0|12.017925721935569|\n",
      "|[0.0,19431.0,2011.0]|              0.0|12.097445131310025|\n",
      "|[0.0,19501.0,2005.0]|              0.0|12.574711981563695|\n",
      "|[0.0,19574.0,2003.0]|              0.0|12.733729108869312|\n",
      "|[0.0,19848.0,2007.0]|              0.0|12.415087493845533|\n",
      "|[0.0,19901.0,2003.0]|              0.0|12.733256235405264|\n",
      "|[0.0,20000.0,1985.0]|              0.0|14.165217302846742|\n",
      "|[0.0,20300.0,1986.0]|              0.0|14.085222127815797|\n",
      "|[0.0,20500.0,1985.0]|              0.0|14.164494254736582|\n",
      "|[0.0,20500.0,1994.0]|              0.0|13.448442139252933|\n",
      "|[0.0,20600.0,1990.0]|              0.0|13.766542914290312|\n",
      "|[0.0,20800.0,1991.0]|              0.0|13.686692348881394|\n",
      "|[0.0,20933.0,2014.0]|              0.0|11.856589056292535|\n",
      "|[0.0,21000.0,1994.0]|              0.0|13.447719091142773|\n",
      "|[0.0,21081.0,2006.0]|              0.0|12.492865803370734|\n",
      "|[0.0,21100.0,1987.0]|              0.0|14.004503904674664|\n",
      "|[0.0,21105.0,2003.0]|              0.0| 12.73151513555598|\n",
      "|[0.0,21198.0,2005.0]|              0.0|12.572257956277781|\n",
      "|[0.0,21200.0,1985.0]|              0.0| 14.16348198738234|\n",
      "|[0.0,21300.0,1991.0]|              0.0|13.685969300771234|\n",
      "|[0.0,21311.0,2013.0]|              0.0|11.935603778086062|\n",
      "|[0.0,21382.0,2009.0]|              0.0|12.253746489913823|\n",
      "|[0.0,21521.0,2000.0]|              0.0|12.969597598022858|\n",
      "|[0.0,21535.0,2007.0]|              0.0|12.412647929521825|\n",
      "|[0.0,21700.0,1988.0]|              0.0| 13.92407490077764|\n",
      "|[0.0,21721.0,2005.0]|              0.0|12.571501647954562|\n",
      "|[0.0,21737.0,2001.0]|              0.0| 12.88972389507444|\n",
      "|[0.0,21996.0,2002.0]|              0.0|12.809788009988495|\n",
      "|[0.0,22000.0,1991.0]|              0.0|13.684957033416993|\n",
      "|[0.0,22143.0,2009.0]|              0.0|12.252646010690171|\n",
      "|[0.0,22446.0,2014.0]|              0.0|11.854401112711145|\n",
      "|[0.0,22608.0,1997.0]|              0.0|13.206709729925933|\n",
      "|[0.0,22675.0,2010.0]|              0.0|12.172315341336116|\n",
      "|[0.0,22723.0,2005.0]|              0.0|12.570052659541773|\n",
      "|[0.0,22817.0,1998.0]|              0.0|13.126846149651016|\n",
      "|[0.0,22900.0,1993.0]|              0.0|13.524532854488996|\n",
      "|[0.0,22905.0,2008.0]|              0.0|12.331105431535121|\n",
      "|[0.0,22938.0,2007.0]|              0.0|12.410619056524695|\n",
      "|[0.0,22973.0,2009.0]|              0.0|12.251445750827287|\n",
      "|[0.0,23134.0,2002.0]|              0.0|12.808142352489739|\n",
      "|[0.0,23389.0,2015.0]|              0.0|11.773476097810516|\n",
      "|[0.0,23496.0,2011.0]|              0.0|12.091566750174337|\n",
      "|[0.0,23595.0,2006.0]|              0.0|12.489230317472789|\n",
      "|[0.0,23900.0,1985.0]|              0.0| 14.15957752758743|\n",
      "|[0.0,23987.0,2009.0]|              0.0| 12.24997940925985|\n",
      "|[0.0,24000.0,1986.0]|              0.0|14.079871571800567|\n",
      "|[0.0,24000.0,1988.0]|              0.0|13.920748879470864|\n",
      "|[0.0,24000.0,1992.0]|              0.0|13.602503494811458|\n",
      "|[0.0,24100.0,1986.0]|              0.0| 14.07972696217854|\n",
      "|[0.0,24200.0,2010.0]|              0.0| 12.17011004460008|\n",
      "|[0.0,24299.0,2007.0]|              0.0|12.408650919568828|\n",
      "|[0.0,24300.0,1987.0]|              0.0|13.999876396769594|\n",
      "|[0.0,24481.0,2005.0]|              0.0| 12.56751042238642|\n",
      "|[0.0,24495.0,2008.0]|              0.0|12.328806138544792|\n",
      "|[0.0,24500.0,1985.0]|              0.0|14.158709869855244|\n",
      "|[0.0,24500.0,1997.0]|              0.0|13.203973715877055|\n",
      "|[0.0,24600.0,1991.0]|              0.0|13.681197183244109|\n",
      "|[0.0,24863.0,2011.0]|              0.0|12.089589936641147|\n",
      "|[0.0,25100.0,1987.0]|              0.0|13.998719519793326|\n",
      "|[0.0,25200.0,1996.0]|              0.0|13.282522794687651|\n",
      "|[0.0,25500.0,1987.0]|              0.0|13.998141081305192|\n",
      "|[0.0,25583.0,1998.0]|              0.0| 13.12284624750555|\n",
      "|[0.0,25625.0,1999.0]|              0.0| 13.04322416529945|\n",
      "|[0.0,25644.0,2002.0]|              0.0|12.804512650976704|\n",
      "|[0.0,25900.0,1988.0]|              0.0|13.918001296652221|\n",
      "|[0.0,25931.0,2005.0]|              0.0|12.565413582866938|\n",
      "|[0.0,25941.0,2003.0]|              0.0|12.724521814234436|\n",
      "|[0.0,26000.0,1985.0]|              0.0|14.156540725524735|\n",
      "|[0.0,26000.0,1989.0]|              0.0| 13.83829534086533|\n",
      "|[0.0,26200.0,1986.0]|              0.0|14.076690160115817|\n",
      "|[0.0,26262.0,2011.0]|              0.0|  12.0875668480289|\n",
      "|[0.0,26298.0,2016.0]|              0.0|11.689708057740717|\n",
      "|[0.0,26400.0,1987.0]|              0.0|13.996839594706898|\n",
      "|[0.0,26500.0,1985.0]|              0.0|14.155817677414547|\n",
      "|[0.0,26565.0,2001.0]|              0.0| 12.88274214252263|\n",
      "|[0.0,26700.0,1986.0]|              0.0|14.075967112005657|\n",
      "|[0.0,26900.0,1991.0]|              0.0|13.677871161937333|\n",
      "|[0.0,26900.0,1994.0]|              0.0|13.439187123442764|\n",
      "|[0.0,26975.0,2012.0]|              0.0| 12.00697443525894|\n",
      "|[0.0,27100.0,1992.0]|              0.0|13.598020596528414|\n",
      "|[0.0,27100.0,1993.0]|              0.0|13.518459250363577|\n",
      "|[0.0,27100.0,1996.0]|              0.0|13.279775211869008|\n",
      "|[0.0,27217.0,2006.0]|              0.0|12.483992556962733|\n",
      "|[0.0,27223.0,2003.0]|              0.0| 12.72266791887995|\n",
      "|[0.0,27234.0,1999.0]|              0.0|13.040897396480943|\n",
      "|[0.0,27300.0,1987.0]|              0.0|13.995538108108576|\n",
      "|[0.0,27498.0,2004.0]|              0.0|12.642708896254504|\n",
      "|[0.0,27600.0,1985.0]|              0.0|  14.1542269715722|\n",
      "|[0.0,27800.0,1989.0]|              0.0|13.835692367668713|\n",
      "|[0.0,27929.0,2006.0]|              0.0|12.482962936453873|\n",
      "|[0.0,27992.0,2000.0]|              0.0|12.960239909381045|\n",
      "|[0.0,28000.0,1991.0]|              0.0|13.676280456094986|\n",
      "|[0.0,28118.0,2005.0]|              0.0|12.562250970433041|\n",
      "|[0.0,28225.0,2007.0]|              0.0|12.402973545807782|\n",
      "|[0.0,28278.0,2013.0]|              0.0|11.925528825718999|\n",
      "|[0.0,28300.0,1994.0]|              0.0| 13.43716258873431|\n",
      "|[0.0,28320.0,2013.0]|              0.0|11.925468089677736|\n",
      "|[0.0,28328.0,2000.0]|              0.0|12.959754021051026|\n",
      "|[0.0,28335.0,2007.0]|              0.0| 12.40281447522355|\n",
      "|[0.0,28389.0,1997.0]|              0.0|13.198349847676155|\n",
      "|[0.0,28458.0,1994.0]|              0.0|13.436934105531492|\n",
      "|[0.0,28600.0,1996.0]|              0.0|  13.2776060675385|\n",
      "|[0.0,28997.0,2011.0]|              0.0|12.083611774866256|\n",
      "|[0.0,29000.0,1988.0]|              0.0|13.913518398369177|\n",
      "|[0.0,29036.0,1996.0]|              0.0|13.276975569586426|\n",
      "|[0.0,29132.0,2004.0]|              0.0| 12.64034597503047|\n",
      "|[0.0,29274.0,2010.0]|              0.0|12.162772552378101|\n",
      "|[0.0,29358.0,2011.0]|              0.0|12.083089734130738|\n",
      "|[0.0,29500.0,1989.0]|              0.0|13.833234004094152|\n",
      "|[0.0,29500.0,1998.0]|              0.0|13.117181888610503|\n",
      "|[0.0,29545.0,2001.0]|              0.0|12.878432775786024|\n",
      "|[0.0,29600.0,1993.0]|              0.0| 13.51484400981272|\n",
      "|[0.0,29792.0,2002.0]|              0.0|12.798514243854754|\n",
      "|[0.0,30201.0,2008.0]|              0.0|12.320554713511541|\n",
      "|[0.0,30210.0,2006.0]|              0.0|12.479664390975273|\n",
      "|[0.0,30545.0,2013.0]|              0.0|11.922250525587486|\n",
      "|[0.0,30751.0,2013.0]|              0.0|11.921952629766082|\n",
      "|[0.0,30800.0,1994.0]|              0.0|13.433547348183453|\n",
      "|[0.0,30921.0,2007.0]|              0.0|12.399074870397754|\n",
      "|[0.0,31212.0,2011.0]|              0.0|12.080408671738212|\n",
      "|[0.0,31228.0,1986.0]|              0.0|14.069419188319955|\n",
      "|[0.0,31492.0,2000.0]|              0.0|12.955178572609867|\n",
      "|[0.0,32315.0,2008.0]|              0.0|12.317497666101758|\n",
      "|[0.0,33300.0,1999.0]|              0.0| 13.03212537680838|\n",
      "|[0.0,33801.0,1994.0]|              0.0|13.429207613426229|\n",
      "|[0.0,34082.0,2003.0]|              0.0|12.712749144904677|\n",
      "|[0.0,35389.0,2003.0]|              0.0|12.710859097144692|\n",
      "|[0.0,35553.0,2004.0]|              0.0|12.631060591199684|\n",
      "|[0.0,35738.0,2005.0]|              0.0|12.551231717234089|\n",
      "|[0.0,36341.0,2011.0]|              0.0|12.072991644224118|\n",
      "|[0.0,36569.0,2008.0]|              0.0|12.311345972780458|\n",
      "|[0.0,37000.0,1989.0]|              0.0|13.822388282441608|\n",
      "|[0.0,37069.0,2007.0]|              0.0|12.390184270835107|\n",
      "|[0.0,37626.0,2004.0]|              0.0| 12.62806283373493|\n",
      "|[0.0,37982.0,2009.0]|              0.0|12.229741292656257|\n",
      "|[0.0,38017.0,1996.0]|              0.0|13.263988179431578|\n",
      "|[0.0,38038.0,2008.0]|              0.0|12.309221657432772|\n",
      "|[0.0,38400.0,1987.0]|              0.0|13.979486440062857|\n",
      "|[0.0,38471.0,2005.0]|              0.0|12.547279536263915|\n",
      "|[0.0,38483.0,2011.0]|              0.0| 12.06989410612016|\n",
      "|[0.0,38681.0,1996.0]|              0.0|13.263027971541277|\n",
      "|[0.0,38700.0,1992.0]|              0.0|13.581245880372506|\n",
      "|[0.0,39420.0,2000.0]|              0.0|12.943713921775043|\n",
      "|[0.0,39444.0,2005.0]|              0.0|12.545872484641507|\n",
      "|[0.0,39497.0,2003.0]|              0.0|12.704918533871535|\n",
      "|[0.0,40027.0,2002.0]|              0.0|12.783713449039595|\n",
      "|[0.0,40174.0,2013.0]|              0.0|11.908326065081866|\n",
      "|[0.0,40800.0,1985.0]|              0.0|14.135138501463729|\n",
      "|[0.0,40987.0,2001.0]|              0.0|12.861886542832934|\n",
      "|[0.0,41849.0,1986.0]|              0.0|14.054060200363779|\n",
      "|[0.0,42000.0,2015.0]|              0.0|11.746562801053813|\n",
      "|[0.0,42291.0,2001.0]|              0.0|12.860000833361624|\n",
      "|[0.0,42300.0,1998.0]|              0.0|13.098671856990194|\n",
      "|[0.0,42500.0,1987.0]|              0.0|13.973557445559464|\n",
      "|[0.0,42581.0,1986.0]|              0.0| 14.05300165793048|\n",
      "|[0.0,43146.0,2001.0]|              0.0|12.858764421093241|\n",
      "|[0.0,43200.0,1987.0]|              0.0|13.972545178205223|\n",
      "|[0.0,43303.0,2003.0]|              0.0|12.699414691656926|\n",
      "|[0.0,43400.0,1986.0]|              0.0|14.051817305126036|\n",
      "|[0.0,43461.0,2002.0]|              0.0|12.778747554618974|\n",
      "|[0.0,44308.0,2003.0]|              0.0| 12.69796136495549|\n",
      "|[0.0,44418.0,1999.0]|              0.0|13.016047679030663|\n",
      "|[0.0,44516.0,2003.0]|              0.0|12.697660576941672|\n",
      "|[0.0,44760.0,2014.0]|              0.0|11.822132921650564|\n",
      "|[0.0,44778.0,2005.0]|              0.0|12.538159007402243|\n",
      "|[0.0,44900.0,2006.0]|              0.0|12.458421237498527|\n",
      "|[0.0,45354.0,2010.0]|              0.0|12.139519325155078|\n",
      "|[0.0,46042.0,2005.0]|              0.0|12.536331141779726|\n",
      "|[0.0,46083.0,1988.0]|              0.0|13.888814736637158|\n",
      "|[0.0,46555.0,1992.0]|              0.0|13.569886794561768|\n",
      "|[0.0,46573.0,1997.0]|              0.0|13.172054034005555|\n",
      "|[0.0,46968.0,2007.0]|              0.0|12.375869364349995|\n",
      "|[0.0,47200.0,1988.0]|              0.0|13.887199447159048|\n",
      "|[0.0,47222.0,2012.0]|              0.0| 11.97769532508579|\n",
      "|[0.0,47591.0,1989.0]|              0.0| 13.80707267737202|\n",
      "|[0.0,47682.0,2010.0]|              0.0|12.136152813154126|\n",
      "|[0.0,48319.0,2009.0]|              0.0|12.214792996026631|\n",
      "|[0.0,48486.0,2009.0]|              0.0|12.214551497957814|\n",
      "|[0.0,48558.0,2000.0]|              0.0|12.930499494513612|\n",
      "|[0.0,48581.0,2004.0]|              0.0|12.612220849641147|\n",
      "|[0.0,48662.0,2003.0]|              0.0|12.691665062012163|\n",
      "|[0.0,48886.0,2001.0]|              0.0|12.850463828788492|\n",
      "|[0.0,49265.0,2010.0]|              0.0|12.133863642837355|\n",
      "|[0.0,49448.0,2000.0]|              0.0|12.929212468877523|\n",
      "|[0.0,49448.0,2002.0]|              0.0| 12.77008977654782|\n",
      "|[0.0,49464.0,2003.0]|              0.0|12.690505292843454|\n",
      "|[0.0,49788.0,2004.0]|              0.0|12.610475411503188|\n",
      "|[0.0,49934.0,2004.0]|              0.0|12.610264281455017|\n",
      "|[0.0,49978.0,2007.0]|              0.0|12.371516614726772|\n",
      "|[0.0,50621.0,2000.0]|              0.0|12.927516198011062|\n",
      "|[0.0,50621.0,2001.0]|              0.0|12.847954851846225|\n",
      "|[0.0,50624.0,2004.0]|              0.0| 12.60926647506298|\n",
      "|[0.0,50691.0,2011.0]|              0.0|12.052240163462272|\n",
      "|[0.0,50885.0,1999.0]|              0.0| 13.00669577477376|\n",
      "|[0.0,51100.0,1996.0]|              0.0|13.245068902580925|\n",
      "|[0.0,51405.0,1991.0]|              0.0|   13.642434574058|\n",
      "|[0.0,51452.0,2000.0]|              0.0|12.926314492051944|\n",
      "|[0.0,53191.0,2005.0]|              0.0|12.525992999900552|\n",
      "|[0.0,53202.0,2004.0]|              0.0| 12.60553843900695|\n",
      "|[0.0,53852.0,1996.0]|              0.0|13.241089245782547|\n",
      "|[0.0,54594.0,2003.0]|              0.0|12.683086819233125|\n",
      "|[0.0,54893.0,2004.0]|              0.0|12.603093090298358|\n",
      "|[0.0,54933.0,2009.0]|              0.0|12.205228515625322|\n",
      "|[0.0,54987.0,2011.0]|              0.0| 12.04602773409971|\n",
      "|[0.0,55825.0,1993.0]|              0.0|13.476920136434387|\n",
      "|[0.0,56100.0,1997.0]|              0.0|13.158277075314402|\n",
      "|[0.0,56410.0,2004.0]|              0.0|12.600899362332115|\n",
      "|[0.0,56900.0,2004.0]|              0.0| 12.60019077518416|\n",
      "|[0.0,58057.0,2016.0]|              0.0|11.643781487879039|\n",
      "|[0.0,58313.0,2013.0]|              0.0|11.882095325741176|\n",
      "|[0.0,58858.0,2007.0]|              0.0|12.358675280290186|\n",
      "|[0.0,59250.0,2004.0]|              0.0|12.596792449066356|\n",
      "|[0.0,61510.0,2011.0]|              0.0|12.036594848454456|\n",
      "|[0.0,63330.0,2012.0]|              0.0|11.954401607168592|\n",
      "|[0.0,63432.0,2011.0]|              0.0|12.033815451518961|\n",
      "|[0.0,63714.0,2002.0]|              0.0|12.749459767868473|\n",
      "|[0.0,64351.0,2014.0]|              0.0|11.793802450597923|\n",
      "|[0.0,64580.0,2010.0]|              0.0|12.111716679222894|\n",
      "|[0.0,65535.0,2009.0]|              0.0|12.189897003497293|\n",
      "|[0.0,68172.0,2009.0]|              0.0|12.186083647764264|\n",
      "|[0.0,69866.0,2010.0]|              0.0|12.104072614602188|\n",
      "|[0.0,69881.0,1999.0]|              0.0|12.979225730972217|\n",
      "|[0.0,70000.0,1990.0]|              0.0|13.695105761005664|\n",
      "|[0.0,70137.0,2010.0]|              0.0|12.103680722526462|\n",
      "|[0.0,70627.0,2003.0]|              0.0|12.659901558532454|\n",
      "|[0.0,72098.0,2000.0]|              0.0|12.896458389486867|\n",
      "|[0.0,73036.0,2004.0]|              0.0|12.576856566572786|\n",
      "|[0.0,73737.0,2000.0]|              0.0|12.894088237781745|\n",
      "|[0.0,74234.0,2010.0]|              0.0|12.097756066311746|\n",
      "|[0.0,75430.0,2003.0]|              0.0|12.652955958386173|\n",
      "|[0.0,75925.0,2015.0]|              0.0|11.697503986778884|\n",
      "|[0.0,76218.0,1999.0]|              0.0|12.970061819223957|\n",
      "|[0.0,76617.0,2008.0]|              0.0|12.253432711348381|\n",
      "|[0.0,78078.0,2005.0]|              0.0|12.490004003265028|\n",
      "|[0.0,80541.0,2000.0]|              0.0|12.884248999098588|\n",
      "|[0.0,80849.0,1998.0]|              0.0| 13.04292629379242|\n",
      "|[0.0,82452.0,2014.0]|              0.0|11.767626662913614|\n",
      "|[0.0,83764.0,2012.0]|              0.0|11.924852077002242|\n",
      "|[0.0,83946.0,2012.0]|              0.0|11.924588887490131|\n",
      "|[0.0,84348.0,2011.0]|              0.0|12.003568902974393|\n",
      "|[0.0,84800.0,1986.0]|              0.0|13.991948921604092|\n",
      "|[0.0,84860.0,2001.0]|              0.0|12.798441963358101|\n",
      "|[0.0,85538.0,2012.0]|              0.0| 11.92228670230736|\n",
      "|[0.0,85543.0,1998.0]|              0.0|13.036138318134164|\n",
      "|[0.0,85866.0,1996.0]|              0.0|13.194793921384672|\n",
      "|[0.0,86065.0,2004.0]|              0.0|12.558015378918014|\n",
      "|[0.0,86342.0,2004.0]|              0.0|12.557614810264994|\n",
      "|[0.0,88212.0,2001.0]|              0.0|12.793594648827536|\n",
      "|[0.0,88650.0,2003.0]|              0.0|12.633838566353319|\n",
      "|[0.0,90906.0,2013.0]|              0.0|11.834962711631732|\n",
      "|[0.0,91316.0,2011.0]|              0.0|11.993492504511096|\n",
      "|[0.0,91477.0,2010.0]|              0.0|12.072821029184496|\n",
      "|[0.0,91494.0,2013.0]|              0.0|11.834112407054164|\n",
      "|[0.0,91679.0,2007.0]|              0.0|12.311212956242514|\n",
      "|[0.0,92051.0,2010.0]|              0.0|12.071990969954015|\n",
      "|[0.0,93603.0,2014.0]|              0.0|11.751501243960632|\n",
      "|[0.0,95590.0,2015.0]|              0.0| 11.66906650460598|\n",
      "|[0.0,96400.0,1986.0]|              0.0|13.975174205448184|\n",
      "|[0.0,96600.0,1999.0]|              0.0|12.940587486061048|\n",
      "|[0.0,97388.0,2014.0]|              0.0| 11.74602776976667|\n",
      "|[0.0,97682.0,2013.0]|              0.0|11.825163963642723|\n",
      "|[0.0,98005.0,2009.0]|              0.0|12.142942259222963|\n",
      "|[0.0,98568.0,2005.0]|              0.0|12.460373491710328|\n",
      "|[0.0,98578.0,2006.0]|              0.0|12.380797684583285|\n",
      "|[0.0,102100.0,198...|              0.0|13.966931456992256|\n",
      "|[0.0,102373.0,200...|              0.0|12.693555134086466|\n",
      "|[0.0,105230.0,198...|              0.0|13.962405175822596|\n",
      "|[0.0,108715.0,198...|              0.0|13.718681492000144|\n",
      "|[0.0,108730.0,200...|              0.0|12.684362300413795|\n",
      "|[0.0,109483.0,200...|              0.0| 12.68327338995988|\n",
      "|[0.0,110000.0,198...|              0.0|14.035068643016416|\n",
      "|[0.0,111900.0,199...|              0.0|13.316268944714125|\n",
      "|[0.0,115895.0,201...|              0.0| 12.03751025167631|\n",
      "|[0.0,119911.0,200...|              0.0|12.509070806244495|\n",
      "|[0.0,120679.0,199...|              0.0|12.905766935171556|\n",
      "|[0.0,121000.0,198...|              0.0|14.019161584592723|\n",
      "|[0.0,122353.0,199...|              0.0| 13.61939828558235|\n",
      "|[0.0,122486.0,199...|              0.0| 12.90315383930141|\n",
      "|[0.0,124000.0,199...|              0.0|13.537455218942625|\n",
      "|[0.0,131362.0,200...|              0.0|12.651634250755137|\n",
      "|[0.0,133200.0,199...|              0.0|13.126344402891249|\n",
      "|[0.0,136335.0,201...|              0.0|11.928390698767743|\n",
      "|[0.0,138317.0,200...|              0.0|12.641576651542692|\n",
      "|[0.0,152100.0,198...|              0.0|13.894626645975393|\n",
      "|[0.0,154600.0,199...|              0.0|13.254520636105752|\n",
      "|[0.0,163081.0,201...|              0.0| 11.96927475542347|\n",
      "|[0.0,168100.0,199...|              0.0|12.837191606306959|\n",
      "|[0.0,175678.0,200...|              0.0| 12.42842635832497|\n",
      "|[0.0,179252.0,198...|              0.0| 13.77580089523596|\n",
      "|[0.0,180414.0,200...|              0.0| 12.66026168512002|\n",
      "|[0.0,183700.0,201...|              0.0|11.621212312796956|\n",
      "|[0.0,187102.0,200...|              0.0|12.252783462774175|\n",
      "|[0.0,189600.0,198...|              0.0|13.919959383877597|\n",
      "|[0.0,195927.0,200...|              0.0|12.319583009794542|\n",
      "|[0.0,198469.0,199...|              0.0| 13.42976587951037|\n",
      "|[0.0,199165.0,199...|              0.0|13.428759396541011|\n",
      "|[0.0,199187.0,200...|              0.0|12.235307389951402|\n",
      "|[0.0,200100.0,199...|              0.0|13.268284604245281|\n",
      "|[0.0,200357.0,199...|              0.0|13.506596996011211|\n",
      "|[0.0,200525.0,200...|              0.0|12.631179244032836|\n",
      "|[0.0,203195.0,200...|              0.0|  12.2295114363003|\n",
      "|[0.0,209698.0,200...|              0.0|12.458791511073969|\n",
      "|[0.0,211300.0,198...|              0.0|13.729456403566587|\n",
      "|[0.0,214118.0,200...|              0.0|12.293277073450383|\n",
      "|[0.0,215163.0,201...|              0.0|11.893959172075881|\n",
      "|[0.0,215900.0,198...|              0.0|13.881927053282737|\n",
      "|[0.0,225440.0,201...|              0.0|11.879097641219488|\n",
      "|[0.0,226998.0,200...|              0.0|11.956405969473053|\n",
      "|[0.0,232100.0,200...|              0.0|12.028589332721737|\n",
      "|[0.0,233302.0,200...|              0.0|11.947289778900029|\n",
      "|[0.0,237859.0,201...|              0.0|11.861138572259136|\n",
      "|[0.0,240410.0,200...|              0.0|12.653063042449531|\n",
      "|[0.0,244042.0,200...|              0.0|12.329565436317864|\n",
      "|[0.0,244141.0,201...|              0.0|11.692931503473261|\n",
      "|[0.0,247730.0,200...|              0.0|12.324232233457252|\n",
      "|[0.0,251027.0,199...|              0.0|13.433323300526723|\n",
      "|[0.0,251089.0,200...|              0.0|11.921568065428914|\n",
      "|[0.0,251399.0,200...|              0.0| 12.63717189108425|\n",
      "|[0.0,253800.0,199...|              0.0| 13.34975192954289|\n",
      "|[0.0,258271.0,201...|              0.0| 11.83162085620961|\n",
      "|[0.0,262973.0,199...|              0.0| 12.77955746575978|\n",
      "|[0.0,263178.0,201...|              0.0|11.665402169726718|\n",
      "|[0.0,264790.0,201...|              0.0|11.503948370289834|\n",
      "|[0.0,266454.0,200...|              0.0|11.978910143168292|\n",
      "|[0.0,268046.0,201...|              0.0|11.817485265655819|\n",
      "|[0.0,270003.0,200...|              0.0|11.894216601517456|\n",
      "|[0.0,272956.0,201...|              0.0|11.730823587049088|\n",
      "|[0.0,276524.0,198...|              0.0| 13.55557487752651|\n",
      "|[0.0,282182.0,200...|              0.0|12.194849980309385|\n",
      "|[0.0,283800.0,199...|              0.0|13.147246350603098|\n",
      "|[0.0,286874.0,201...|              0.0|11.631135473689596|\n",
      "|[0.0,287845.0,200...|              0.0|12.107099391248767|\n",
      "|[0.0,290641.0,200...|              0.0|12.341740144711252|\n",
      "|[0.0,290970.0,200...|              0.0|12.261703032889898|\n",
      "|[0.0,291486.0,200...|              0.0|12.340518193405074|\n",
      "|[0.0,292230.0,200...|              0.0|12.419003643981966|\n",
      "|[0.0,293989.0,200...|              0.0|11.939091883741327|\n",
      "|[0.0,299008.0,200...|              0.0|12.250079311470813|\n",
      "|[0.0,300253.0,199...|              0.0|12.805208344830476|\n",
      "|[0.0,301180.0,199...|              0.0| 12.88342915979905|\n",
      "|[0.0,302997.0,200...|              0.0|11.846504102823644|\n",
      "|[0.0,303666.0,199...|              0.0|12.959395510760174|\n",
      "|[0.0,305241.0,200...|              0.0|12.002381755234921|\n",
      "|[0.0,309578.0,200...|              0.0|12.075671382092196|\n",
      "|[0.0,310200.0,199...|              0.0|13.029508064221318|\n",
      "|[0.0,310343.0,200...|              0.0|12.472371849307876|\n",
      "|[0.0,316500.0,199...|              0.0|12.781713619538664|\n",
      "|[0.0,317200.0,198...|              0.0|13.496753467668071|\n",
      "|[0.0,318800.0,199...|              0.0|13.335317021385833|\n",
      "|[0.0,319134.0,201...|              0.0| 11.42536171729185|\n",
      "|[0.0,319507.0,200...|              0.0|12.459119823544711|\n",
      "|[0.0,319676.0,201...|              0.0|11.742823317799832|\n",
      "|[0.0,321246.0,200...|              0.0|12.217921023722965|\n",
      "|[0.0,324600.0,199...|              0.0|13.247368317143042|\n",
      "|[0.0,325800.0,199...|              0.0|13.166071655513775|\n",
      "|[0.0,329700.0,199...|              0.0|12.603502457100518|\n",
      "|[0.0,335304.0,200...|              0.0|12.038469110727789|\n",
      "|[0.0,338050.0,199...|              0.0|12.591427553660708|\n",
      "|[0.0,342224.0,201...|              0.0|11.551094047893969|\n",
      "|[0.0,346468.0,200...|              0.0|12.420131623348198|\n",
      "|[0.0,346889.0,200...|              0.0| 12.33996147067458|\n",
      "|[0.0,347150.0,199...|              0.0|12.737390770385332|\n",
      "|[0.0,357283.0,201...|              0.0|11.370194592582209|\n",
      "|[0.0,358600.0,198...|              0.0|13.516446430310964|\n",
      "|[0.0,359200.0,199...|              0.0|13.117772041754534|\n",
      "|[0.0,362111.0,199...|              0.0|12.556633032503186|\n",
      "|[0.0,366100.0,199...|              0.0|12.869109939339666|\n",
      "|[0.0,370800.0,199...|              0.0|12.703190594774384|\n",
      "|[0.0,373400.0,199...|              0.0| 12.93811478309604|\n",
      "|[0.0,374365.0,200...|              0.0|11.743299107770639|\n",
      "|[0.0,379250.0,200...|              0.0| 11.97491896622887|\n",
      "|[0.0,380242.0,200...|              0.0|12.053045784943123|\n",
      "|[0.0,381082.0,200...|              0.0|12.370076448777468|\n",
      "|[0.0,386513.0,200...|              0.0| 12.04397731554539|\n",
      "|[0.0,387636.0,201...|              0.0|11.485423926336011|\n",
      "|[0.0,388746.0,200...|              0.0|11.961186836520568|\n",
      "|[0.0,390773.0,200...|              0.0|11.799132907152227|\n",
      "|[0.0,394286.0,200...|              0.0|11.714491424965331|\n",
      "|[0.0,395191.0,200...|              0.0|11.872305400215623|\n",
      "|[0.0,426981.0,200...|              0.0|11.826334001371094|\n",
      "|[0.0,436026.0,200...|              0.0|12.211060791882403|\n",
      "|[0.0,441200.0,198...|              0.0|13.476560228675993|\n",
      "|[0.0,444450.0,199...|              0.0|13.074053685135652|\n",
      "|[0.0,445779.0,200...|              0.0|11.878711630786086|\n",
      "|[0.0,493148.0,201...|              0.0|11.173720729606117|\n",
      "|[0.0,510880.0,201...|              0.0| 11.38676258992166|\n",
      "|[0.0,512001.0,200...|              0.0| 11.54426420838837|\n",
      "|[0.0,524974.0,201...|              0.0| 11.28681996362738|\n",
      "|[0.0,526123.0,201...|              0.0| 11.12603570674051|\n",
      "|[0.0,534800.0,199...|              0.0|12.704714853133652|\n",
      "|[0.0,544037.0,200...|              0.0|11.975305146862752|\n",
      "|[0.0,547604.0,200...|              0.0|11.731462883150272|\n",
      "|[0.0,551700.0,199...|              0.0|12.282469096185707|\n",
      "|[0.0,561751.0,200...|              0.0|12.188373036910235|\n",
      "|[0.0,573940.0,200...|              0.0|11.932062531586013|\n",
      "|[0.0,581943.0,200...|              0.0|12.159173462029202|\n",
      "|[0.0,616895.0,199...|              0.0| 12.18819085310085|\n",
      "|[0.0,627589.0,199...|              0.0|12.490971684779964|\n",
      "|[0.0,635118.0,199...|              0.0|12.480084026337067|\n",
      "|[0.0,644000.0,200...|              0.0|11.512503645729822|\n",
      "|[0.0,656944.0,199...|              0.0|12.209837491737431|\n",
      "|[0.0,659097.0,199...|              0.0|12.684092123564142|\n",
      "|[0.0,673524.0,199...|              0.0|12.663229293393329|\n",
      "|[0.0,681800.0,198...|              0.0|13.128629478062948|\n",
      "|[0.0,688296.0,201...|              0.0|11.050640636729526|\n",
      "|[0.0,689000.0,199...|              0.0|12.799972200617105|\n",
      "|[0.0,706661.0,200...|              0.0|11.421889810467292|\n",
      "|[0.0,710300.0,199...|              0.0| 12.61004765879423|\n",
      "|[0.0,771963.0,200...|              0.0| 11.32745683508685|\n",
      "|[0.0,788700.0,199...|              0.0|12.257989676625272|\n",
      "|[0.0,844400.0,199...|              0.0|12.018319424822806|\n",
      "|[0.0,878300.0,199...|              0.0|12.446664839942486|\n",
      "|[0.0,892200.0,199...|              0.0| 11.79007333316099|\n",
      "|[0.0,1261500.0,19...|              0.0| 11.57427538364999|\n",
      "|[0.0,2161906.0,20...|              0.0| 9.078781477808548|\n",
      "|[0.0,3544844.0,19...|              0.0| 8.511024294015556|\n",
      "|[0.0,5099973.0,19...|              0.0| 5.864351394154966|\n",
      "|[0.0,5508805.0,19...|              0.0| 5.352702330367038|\n",
      "|[0.0,8129872.0,19...|              0.0|1.8806326330766296|\n",
      "|[0.0,8483426.0,19...|              0.0|1.3693595299916126|\n",
      "|  [1.0,976.0,2001.0]|           102.46|12.930230907514613|\n",
      "| [1.0,1593.0,2000.0]|            62.77|  13.0089000123115|\n",
      "| [1.0,2384.0,1993.0]|            41.95|13.564685573355177|\n",
      "| [1.0,2402.0,1995.0]|            41.63|13.405536851293505|\n",
      "| [1.0,2542.0,1999.0]|            39.34| 13.08708901316325|\n",
      "| [1.0,2799.0,1992.0]|            35.73|13.643646789588587|\n",
      "| [1.0,3037.0,2013.0]|            32.93|11.972514349226287|\n",
      "| [1.0,3217.0,2002.0]|            31.08|12.847428859719969|\n",
      "| [1.0,3425.0,2003.0]|             29.2|12.767566725541286|\n",
      "| [1.0,3665.0,2004.0]|            27.29|12.687658316283546|\n",
      "| [1.0,3878.0,2005.0]|            25.79|12.607788951623775|\n",
      "| [1.0,3932.0,1991.0]|            25.43|13.721569708735814|\n",
      "| [1.0,4229.0,1990.0]|            23.65|13.800701564323191|\n",
      "| [1.0,4593.0,2002.0]|            21.77| 12.84543903132078|\n",
      "| [1.0,5153.0,1992.0]|            19.41|13.640242679085901|\n",
      "| [1.0,5180.0,2002.0]|            19.31|12.844590172839446|\n",
      "| [1.0,5420.0,2008.0]|            18.45|12.366875032757491|\n",
      "| [1.0,5470.0,2013.0]|            18.28|11.968995997122192|\n",
      "| [1.0,5799.0,1990.0]|            17.24|13.798431193257272|\n",
      "| [1.0,5809.0,2009.0]|            17.21|12.286751155162904|\n",
      "| [1.0,5957.0,2015.0]|            16.79|11.809169055933182|\n",
      "| [1.0,6164.0,2004.0]|            16.22|12.684044521828923|\n",
      "| [1.0,6226.0,1992.0]|            16.06|13.638691017841495|\n",
      "| [1.0,6656.0,2011.0]|            15.02|12.126403619334582|\n",
      "| [1.0,6706.0,2011.0]|            14.91|12.126331314523554|\n",
      "| [1.0,6768.0,1996.0]|            14.78|13.319661849030666|\n",
      "| [1.0,6903.0,2015.0]|            14.49|11.807801048908743|\n",
      "| [1.0,7068.0,2003.0]|            14.15|12.762298597010613|\n",
      "| [1.0,7134.0,2005.0]|            14.02|12.603080462330354|\n",
      "| [1.0,7320.0,2002.0]|            13.66|12.841495526927929|\n",
      "| [1.0,7565.0,2015.0]|            13.22|11.806843733210883|\n",
      "| [1.0,7593.0,1990.0]|            13.17| 13.79583689663798|\n",
      "| [1.0,7788.0,2009.0]|            12.84|12.283889330742852|\n",
      "| [1.0,7959.0,2008.0]|            12.56|12.363203394454047|\n",
      "| [1.0,8112.0,2001.0]|            12.33|12.919911564886291|\n",
      "| [1.0,8183.0,2007.0]|            12.22|12.442440815065538|\n",
      "| [1.0,8291.0,2009.0]|            12.06|12.283161944344045|\n",
      "| [1.0,8361.0,1996.0]|            11.96| 13.31735821775166|\n",
      "| [1.0,8713.0,2002.0]|            11.48|12.839481114893005|\n",
      "| [1.0,8823.0,2004.0]|            11.33|12.680199351979041|\n",
      "| [1.0,9023.0,1995.0]|            11.08|13.395962248218666|\n",
      "| [1.0,9783.0,2015.0]|            10.22|11.803636291794191|\n",
      "| [1.0,9974.0,1990.0]|            10.03|13.792393741537381|\n",
      "|[1.0,10033.0,2000.0]|             9.97| 12.99669496021184|\n",
      "|[1.0,10115.0,2006.0]|             9.89|12.519208303332704|\n",
      "|[1.0,10489.0,1990.0]|             9.53|13.791649001983899|\n",
      "|[1.0,10536.0,2011.0]|             9.49|12.120792765999681|\n",
      "|[1.0,10790.0,2002.0]|             9.27|12.836477573043368|\n",
      "|[1.0,11406.0,2004.0]|             8.77|12.676464085441921|\n",
      "|[1.0,11449.0,1995.0]|             8.73| 13.39245401878813|\n",
      "|[1.0,11584.0,2005.0]|             8.63|12.596645334149855|\n",
      "|[1.0,11640.0,2002.0]|             8.59|12.835248391256073|\n",
      "|[1.0,12453.0,2002.0]|             8.03|12.834072715028924|\n",
      "|[1.0,12833.0,1993.0]|             7.79|13.549575313948878|\n",
      "|[1.0,13000.0,1985.0]|             7.69|14.185824585198873|\n",
      "|[1.0,13200.0,1996.0]|             7.58| 13.31036055814144|\n",
      "|[1.0,14619.0,2015.0]|             6.84|11.796642970472618|\n",
      "|[1.0,14800.0,1988.0]|             6.76|13.944537573507716|\n",
      "|[1.0,15678.0,2010.0]|             6.38|12.192918285399571|\n",
      "|[1.0,15746.0,2003.0]|             6.35| 12.74974937401052|\n",
      "|[1.0,16000.0,1990.0]|             6.25|13.783679565713612|\n",
      "|[1.0,16500.0,1997.0]|             6.06|13.226027094449506|\n",
      "|[1.0,17917.0,2001.0]|             5.58|12.905732591445883|\n",
      "|[1.0,18966.0,1987.0]|             5.27|14.018074482818633|\n",
      "|[1.0,19400.0,1995.0]|             5.15|13.380956107740218|\n",
      "|[1.0,19651.0,2006.0]|             5.09| 12.50541832977558|\n",
      "|[1.0,19879.0,2001.0]|             5.03|12.902895350661566|\n",
      "|[1.0,20200.0,1987.0]|             4.95|14.016290000082734|\n",
      "|[1.0,20500.0,1994.0]|             4.88|13.458926748062709|\n",
      "|[1.0,20592.0,2002.0]|             4.86|12.822302937891607|\n",
      "|[1.0,20700.0,1989.0]|             4.83| 13.85644425964287|\n",
      "|[1.0,20700.0,1996.0]|             4.83|13.299514836488925|\n",
      "|[1.0,20765.0,1998.0]|             4.82|  13.1402981479049|\n",
      "|[1.0,20900.0,1987.0]|             4.78| 14.01527773272852|\n",
      "|[1.0,21000.0,1985.0]|             4.76|14.174255815436169|\n",
      "|[1.0,21454.0,2009.0]|             4.66|12.264126979795748|\n",
      "|[1.0,21800.0,1987.0]|             4.59|14.013976246130198|\n",
      "|[1.0,22000.0,1986.0]|             4.55|14.093248373051011|\n",
      "|[1.0,22000.0,1986.0]|             4.55|14.093248373051011|\n",
      "|[1.0,22178.0,2011.0]|             4.51| 12.10395731380251|\n",
      "|[1.0,22300.0,1988.0]|             4.48|13.933691851855201|\n",
      "|[1.0,22469.0,2014.0]|             4.45|11.864852461307862|\n",
      "|[1.0,22554.0,1997.0]|             4.43| 13.21727242793159|\n",
      "|[1.0,22681.0,2010.0]|             4.41| 12.18279127356854|\n",
      "|[1.0,22983.0,2007.0]|             4.35|12.421038591004532|\n",
      "|[1.0,23115.0,1999.0]|             4.33| 13.05733847562226|\n",
      "|[1.0,23393.0,2008.0]|             4.27|12.340884345389355|\n",
      "|[1.0,23600.0,1997.0]|             4.24|13.215759811285125|\n",
      "|[1.0,24300.0,1987.0]|             4.12| 14.01036100557937|\n",
      "|[1.0,24624.0,2012.0]|             4.06|12.020858816282725|\n",
      "|[1.0,24900.0,1995.0]|             4.02|13.373002578528371|\n",
      "|[1.0,24949.0,2013.0]|             4.01|11.940827488846253|\n",
      "|[1.0,25089.0,2002.0]|             3.99|12.815799843188756|\n",
      "|[1.0,25331.0,2003.0]|             3.95|12.735888541738603|\n",
      "|[1.0,25332.0,2001.0]|             3.95|12.895009787972072|\n",
      "|[1.0,25426.0,1991.0]|             3.93|13.690487316575883|\n",
      "|[1.0,26300.0,1995.0]|              3.8|13.370978043819918|\n",
      "|[1.0,26480.0,1992.0]|             3.78|13.609401784994787|\n",
      "|[1.0,26726.0,2003.0]|             3.74|12.733871237511238|\n",
      "|[1.0,26900.0,1985.0]|             3.72|14.165723847736189|\n",
      "|[1.0,27047.0,2007.0]|              3.7|12.415161655965107|\n",
      "|[1.0,27500.0,1987.0]|             3.64|14.005733497674271|\n",
      "|[1.0,27900.0,1999.0]|             3.58|13.050418905207948|\n",
      "|[1.0,28500.0,1997.0]|             3.51|13.208673939805465|\n",
      "|[1.0,28664.0,2007.0]|             3.49|12.412823318376809|\n",
      "|[1.0,29224.0,1987.0]|             3.42|14.003240427790416|\n",
      "|[1.0,30136.0,1996.0]|             3.32|13.285869472553827|\n",
      "|[1.0,32425.0,1990.0]|             3.08|13.759927435294571|\n",
      "|[1.0,32667.0,2003.0]|             3.06|12.725279979866201|\n",
      "|[1.0,32892.0,1989.0]|             3.04|13.838813454524512|\n",
      "|[1.0,33336.0,1997.0]|              3.0| 13.20168061848392|\n",
      "|[1.0,33475.0,2003.0]|             2.99| 12.72411153412017|\n",
      "|[1.0,33595.0,2000.0]|             2.98|12.962622041068272|\n",
      "|[1.0,35200.0,1985.0]|             2.84|14.153721249107406|\n",
      "|[1.0,36391.0,2001.0]|             2.75| 12.87901740987138|\n",
      "|[1.0,37231.0,2011.0]|             2.69|12.082189227397777|\n",
      "|[1.0,37335.0,2001.0]|             2.68|12.877652295039383|\n",
      "|[1.0,37467.0,1991.0]|             2.67|13.673074871986813|\n",
      "|[1.0,37608.0,2001.0]|             2.66|12.877257510771216|\n",
      "|[1.0,38000.0,1985.0]|             2.63|14.149672179690441|\n",
      "|[1.0,38600.0,1987.0]|             2.59|13.989681829628552|\n",
      "|[1.0,38640.0,2004.0]|             2.59| 12.63708110097727|\n",
      "|[1.0,40531.0,2006.0]|             2.47|12.475223840694952|\n",
      "|[1.0,40926.0,2003.0]|             2.44|12.713336671182446|\n",
      "|[1.0,41900.0,1994.0]|             2.39| 13.42798028894748|\n",
      "|[1.0,42375.0,1990.0]|             2.36|13.745538777902226|\n",
      "|[1.0,42852.0,2005.0]|             2.33|12.551428797532367|\n",
      "|[1.0,42900.0,1990.0]|             2.33|13.744779577386566|\n",
      "|[1.0,47227.0,2008.0]|             2.12|12.306418088073855|\n",
      "|[1.0,48900.0,1990.0]|             2.04|13.736103000064531|\n",
      "|[1.0,48976.0,2007.0]|             2.04|12.383450211949338|\n",
      "|[1.0,49401.0,2008.0]|             2.02|12.303274274890839|\n",
      "|[1.0,52400.0,1985.0]|             1.91|14.128848394117597|\n",
      "|[1.0,54147.0,2004.0]|             1.85|12.614656486888492|\n",
      "|[1.0,54245.0,2012.0]|             1.84|11.978024000140124|\n",
      "|[1.0,55621.0,2010.0]|              1.8|12.135156864070638|\n",
      "|[1.0,56039.0,2011.0]|             1.78|12.054991049685668|\n",
      "|[1.0,56327.0,1998.0]|             1.78| 13.08887207411729|\n",
      "|[1.0,57514.0,2006.0]|             1.74|12.450664788584959|\n",
      "|[1.0,58700.0,1988.0]|              1.7|13.881053949434943|\n",
      "|[1.0,58790.0,2004.0]|              1.7| 12.60794226213747|\n",
      "|[1.0,62046.0,2005.0]|             1.61|12.523672426679212|\n",
      "|[1.0,63516.0,2008.0]|             1.57| 12.28286262674078|\n",
      "|[1.0,64534.0,2014.0]|             1.55|11.804022423799381|\n",
      "|[1.0,64680.0,2008.0]|             1.55|12.281179370740318|\n",
      "|[1.0,65600.0,1987.0]|             1.52|13.950637231679451|\n",
      "|[1.0,67802.0,2015.0]|             1.47|11.719735235186448|\n",
      "|[1.0,67819.0,2012.0]|             1.47|11.958394690045282|\n",
      "|[1.0,67856.0,2001.0]|             1.47|12.833515992298487|\n",
      "|[1.0,68187.0,2009.0]|             1.47|12.196546565130745|\n",
      "|[1.0,68740.0,2006.0]|             1.45| 12.43443091241545|\n",
      "|[1.0,71307.0,2016.0]|              1.4|11.635105321769345|\n",
      "|[1.0,75365.0,2012.0]|             1.33|11.947482447966621|\n",
      "|[1.0,77166.0,2006.0]|              1.3|12.422246105662907|\n",
      "|[1.0,77270.0,2011.0]|             1.29|12.024288980831699|\n",
      "|[1.0,78498.0,2003.0]|             1.27|12.659003943991934|\n",
      "|[1.0,80672.0,2011.0]|             1.24|12.019369361490135|\n",
      "|[1.0,86452.0,2013.0]|             1.16| 11.85188823300686|\n",
      "|[1.0,87121.0,1999.0]|             1.15| 12.96477964094339|\n",
      "+--------------------+-----------------+------------------+\n",
      "only showing top 1000 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results = regressor.evaluate(test_data)\n",
    "pred_results.predictions.show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|Num_Suicides_100k|\n",
      "+-----------------+\n",
      "|             6.71|\n",
      "|             5.19|\n",
      "|             4.83|\n",
      "|             4.59|\n",
      "|             3.28|\n",
      "|             2.81|\n",
      "|             2.15|\n",
      "|             1.56|\n",
      "|             0.73|\n",
      "|              0.0|\n",
      "|              0.0|\n",
      "|              0.0|\n",
      "|             5.49|\n",
      "|             5.33|\n",
      "|             4.48|\n",
      "|             4.46|\n",
      "|             2.85|\n",
      "|             2.71|\n",
      "|             2.03|\n",
      "|             1.91|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suicides.select('Num_Suicides_100k').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+----+-----------+-----------------+----------+----------+\n",
      "|           country|year| sex|        age|Num_Suicides_100k|suicide_no|population|\n",
      "+------------------+----+----+-----------+-----------------+----------+----------+\n",
      "|Russian Federation|1994|male|35-54 years|            117.3|     22338|  19044200|\n",
      "+------------------+----+----+-----------+-----------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxSuicide = max(suicides.select('suicide_no').collect())[0]\n",
    "PaisxSuicides = suicides.select('country' ,'year' ,'sex' , 'age' , 'Num_Suicides_100k', 'suicide_no','population').filter(\"suicide_no = 22338\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224.97"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(suicides.select('Num_Suicides_100k').collect())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(suicide_no=22338)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(suicides.select('suicide_no').collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #hasta aqui\n",
    "\n",
    "### -------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aquí empezamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos el transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid param value given for param \"inputCols\". Could not convert [DataFrame[sex: string], ['sex_vec']] to list of strings",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/ml/param/__init__.py\u001b[0m in \u001b[0;36m_set\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/ml/param/__init__.py\u001b[0m in \u001b[0;36mtoListString\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTypeConverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not convert %s to list of strings\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert [DataFrame[sex: string], ['sex_vec']] to list of strings",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-ca9c99fc29d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mvec_assembler_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVectorAssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvar_corr\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/ml/feature.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputCols, outputCol, handleInvalid)\u001b[0m\n\u001b[1;32m   2795\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandleInvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2796\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2797\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mkeyword_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/ml/feature.py\u001b[0m in \u001b[0;36msetParams\u001b[0;34m(self, inputCols, outputCol, handleInvalid)\u001b[0m\n\u001b[1;32m   2805\u001b[0m         \"\"\"\n\u001b[1;32m   2806\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/ml/param/__init__.py\u001b[0m in \u001b[0;36m_set\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid param value given for param \"%s\". %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_paramMap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid param value given for param \"inputCols\". Could not convert [DataFrame[sex: string], ['sex_vec']] to list of strings"
     ]
    }
   ],
   "source": [
    "import pyspark.ml.feature as ft\n",
    "encoder_1 = ft.OneHotEncoder(inputCol='sex', outputCol='sex_vec')\n",
    "var_corr= suicides.select('sex')\n",
    "#añadir mas varibles \n",
    "    \n",
    "vec_assembler_1 = ft.VectorAssembler(inputCols = [var_corr ,[encoder_1.getOutputCol()]], outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuosDataFrame = spark.createDataFrame([\n",
    "    ('male' , 0),\n",
    "    ('female' , 1)\n",
    "],['sexBin' , 'feature'])\n",
    "binarizer = ft.Binarizer(threshold=1, inputCol=\"feature\", outputCol=\"binarized_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Binarizer' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-1b2627e8cbe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbinarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Binarizer' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex_vec']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[encoder_1.getOutputCol()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro obejtivo es que esta variable sea de tipo binario, en el caso del sexo, la variable viene dada como un string 'male' o 'female' y nostros lo que queremos es que esta variable nos aparezca en binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ\n",
    "\n",
    "suicides = suicides.withColumn('sex', suicides['sex'].cast(typ.DoubleType()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el comando withColum, vamos a sobreescribir la variable 'sex', ya que si el nombre no se cambia aplicando dicho comando, la variable se sustituye por el nuevo valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['year','suicide_no','PIB_PerCapita','population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature as ft\n",
    "\n",
    "featuresCreator = ft.VectorAssembler(inputCols = labels ,outputCol = 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # OJO revisar:  nostros no le hemos aplicado el encoder al Vect Assembler\n",
    "   ### REVISAR COMO ESTÁ HECHO ABAJO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hacemos con este bucle es,para todo el conjuto de columnas que esté desde la segunda hasta el final, le aplicamos el encoder y lo añadimos a una unica columna de salida (features: características)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresCreator = ft.VectorAssembler(\n",
    "    inputCols=[\n",
    "        col[0] \n",
    "        for col \n",
    "        in labels[2:]] + [encoder.getOutputCol()], outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27820"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicides.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos el Estimator - REGRESIÓN LOGÍSTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.classification as cl\n",
    "\n",
    "logistic = cl.LogisticRegression(\n",
    "    maxIter=10, \n",
    "    regParam=0.01,\n",
    "    labelCol='Num_Suicides_100k'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos el Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Pipeline es una funcion que se encarga de ejecutar los trasformadores y los algoritmos en un solo paso. Es como una tubería que transporta estimators y transformers hasta su ejecucion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[featuresCreator, logistic])\n",
    "#pipeline = Pipeline(stages=[encoder, featuresCreator, logistic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OJO: revisar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Pipeline va a pasar por 3 fases: la primera es el trasformer de encoder, la segunda es el Vector assembler, que será el features, y por ultimo el estimator (algortimo) que vamos a ejecutar, en nuestro caso es la Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenemos los datos en el formato apropiado, vamos a guardar el 80% de los datos para el entrenamiento y el 20% para el test. Para ello, partimos nuestro data set inicial (el que contiene la variable objetivo) en estos dos conjuntos. El 80% de los datos los ultilizaremos para entrenar el modelo, y el 20% restante nos servirá para poder predecir como de bien (o de mal) ha aprendido el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'suicides' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-673d36f0e953>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msuicides_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuicides_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuicides\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandomSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m666\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#seed numero aleatorio a partir del cual el modelo empieza a iterar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'suicides' is not defined"
     ]
    }
   ],
   "source": [
    "suicides_train, suicides_test = suicides.randomSplit([0.8, 0.2], seed=666) \n",
    "\n",
    "#seed numero aleatorio a partir del cual hace la particion del DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable train entrenará el modelo (para que consiga 'aprender') e intentará predecir/adivinar cual será el valor correspondiente a los datos de la variable test. Vamos con un ejemplo para que quede más claro: en nuestro DataSet interemos predecir cual es el numero de suidcidios por cada 100.000 habitantes, supongamos que nuestro dataset contiene 100 datos de entrada, de esos 100 suicidios cogeremos 60 para que el modelo aprenda (conjunto de entrenamiento 'train') y una vez el modelo haya aprendido, comparará ese aprendizaje con los restante 40 valores. ¿Cómo? bien, pues el algoritmo predecirá el valor que estime óptimo para ese dato, y se compara con el dato real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|Num_Suicides_100k|\n",
      "+-----------------+\n",
      "|            10.65|\n",
      "|             9.13|\n",
      "|            17.52|\n",
      "|            17.95|\n",
      "|             76.4|\n",
      "|             8.51|\n",
      "|             3.26|\n",
      "|             0.66|\n",
      "|            73.73|\n",
      "|             14.9|\n",
      "|             15.5|\n",
      "|             13.4|\n",
      "|            19.98|\n",
      "|            43.03|\n",
      "|            40.11|\n",
      "|            26.72|\n",
      "|             2.86|\n",
      "|            12.32|\n",
      "|            17.56|\n",
      "|             49.8|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suicides.select('Num_Suicides_100k').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicides.select('Num_Suicides_100k').filter(\"Num_Suicides_100k > 150\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o141.fit.\n: org.apache.spark.SparkException: Classification labels should be in [0 to 150]. Found 18600 invalid labels.\n\tat org.apache.spark.ml.classification.LogisticRegression$$anonfun$train$1.apply(LogisticRegression.scala:569)\n\tat org.apache.spark.ml.classification.LogisticRegression$$anonfun$train$1.apply(LogisticRegression.scala:494)\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:494)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:489)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:279)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-89d3b2014196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuicides_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o141.fit.\n: org.apache.spark.SparkException: Classification labels should be in [0 to 150]. Found 18600 invalid labels.\n\tat org.apache.spark.ml.classification.LogisticRegression$$anonfun$train$1.apply(LogisticRegression.scala:569)\n\tat org.apache.spark.ml.classification.LogisticRegression$$anonfun$train$1.apply(LogisticRegression.scala:494)\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:494)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:489)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:279)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(suicides_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico la función Pipeline a todo el conjunto de entrenamiento mediante el comando .fit, esto lo que hace es aplicar los trasformers y los estimators al DataFrame. \n",
    "\n",
    "LO ENTRENA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = model.transform(suicides_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos que ver como de bien entrena el modelo, para ello lo vamos a comparar con la parte que hemos reservado para el test. Aplicamos el comando .trasform al modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Albania', year=1987, sex='female', age='75+ years', suicide_no=1, population=35600, Num_Suicides_100k=2.81, country-year='Albania1987', IDH_Y=None, PIB_Y=None, PIB_PerCapita=796, generation='G.I. Generation', features=DenseVector([1987.0, 1.0, 796.0, 35600.0]), rawPrediction=DenseVector([inf, -inf]), probability=DenseVector([1.0, 0.0]), prediction=0.0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, en esta parte aparecen columnas nuevas, que corresponde con todo lo que habíamos ejecutado antes: como 'features' que son las colunmas que yo he metido por parámetro, 'rawPrediction' y 'probability' que las ha obtenido del test, y por último, la predicción 'prediction'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARTE DE EVALUACIÓN: Vamos a ver cómo de bueno es el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.7882520978396715\n"
     ]
    }
   ],
   "source": [
    "import pyspark.ml.evaluation as ev\n",
    "\n",
    "evaluator = ev.BinaryClassificationEvaluator(\n",
    "    rawPredictionCol='probability', \n",
    "    labelCol='Num_Suicides_100k')\n",
    "\n",
    "print(evaluator.evaluate(test_model, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(test_model, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la libreria evaluation, en este caso, la evaluacion de la regresion logistica corresponde con la de 'binary clasification metrics'. Esta evalucacion nos la devuelve en forma de area, bajo la curva de PR (precission-recall) y de ROC (Receiver Operating Characteristic). Antes de describir un poco ambas gráficas, vamos a describir el \n",
    "\n",
    "    recall = [verdaderos postivos / (verdaderos positivos + falsos negativos)]\n",
    "    precision = [verdaderos postivos / (verdaderos positivos + falsos positivos)]\n",
    "\n",
    "\n",
    "PR: Lo ideal sería una curva que se acerque lo máximo posible a la esquina superior derecha (alta precisión y alto recall)\n",
    "\n",
    "\n",
    "\n",
    "ROC: en este gráfico nos interesa que la curva se acerque lo máximo posible a la esquina superior izquierda de la gráfica, de manera que el hecho de aumentar la sensibilidad (el recall) no haga que nuestro modelo introduzca más falsos positivos.\n",
    "\n",
    "\n",
    "*foto de un grafico de de las rectas ROC y PR\n",
    "\n",
    "\n",
    "\n",
    "ACC: accuracy (acierto); lo que yo acierto (verdaderos positivos + falsos negativos)/(todas las predicciones totales) \n",
    "*formula del ACCURACY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________________________________________________\n",
    "\n",
    "Diferencias entre curvas ROC y PR:\n",
    "\n",
    "Por lo general, usaremos la curva PR o el Average Precision cuando tengamos problemas de datasets no balanceados, es decir, cuando la clase positiva ocurre pocas veces. Cuando hay pocos ejemplos positivos, la curva ROC o el ROC AUC puede dar un valor alto, sin embargo, la curva PR estará lejos de su valor óptimo, poniendo de manifiesto un indicador de precisión relacionado con la baja probabilidad de la clase positiva.\n",
    "Será una opción interesante usar la curva ROC y el ROC AUC cuando tengamos un dataset más balanceado o queramos poner de manifiesto un indicador más relacionado con falsas alarmas (falsos positivos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decir que significa cada uno de los valores obtenidos\n",
    "overfitting = valor > 0.9\n",
    "\n",
    "underfitting = valor < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando con Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Num_Suicides_100k\", outputCol=\"Num_Suicides_100k_indexer\").fit(suicides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "suicides_train, suicides_test = suicides.randomSplit([0.8 , 0.2], seed=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cl.RandomForestClassifier(\n",
    "    numTrees=5, \n",
    "    maxDepth=5, \n",
    "    labelCol='Num_Suicides_100k_indexer')\n",
    "\n",
    "#indexer = StringIndexer(inputCol=\"INFANT_ALIVE_AT_REPORT\", outputCol=\"INFANT_ALIVE_AT_REPORT_indexer\").fit(birthsDF)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        indexer,\n",
    "        featuresCreator, \n",
    "        classifier])\n",
    "\n",
    "model = pipeline.fit(suicides_train)\n",
    "test = model.transform(suicides_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Albania', year=1987, sex=None, age='35-54 years', suicide_no=16, population=308000, Num_Suicides_100k=5.19, country-year='Albania1987', IDH_Y=None, PIB_Y=None, PIB_PerCapita=796, generation='Silent', Num_Suicides_100k_indexer=165.0, features=DenseVector([1987.0, 16.0, 796.0, 308000.0]), rawPrediction=DenseVector([0.0, 0.0067, 0.0034, 0.005, 0.0039, 0.0057, 0.0048, 0.0038, 0.0015, 0.0052, 0.0076, 0.0045, 0.0016, 0.0036, 0.0034, 0.0064, 0.0044, 0.0046, 0.0053, 0.0052, 0.003, 0.0085, 0.0014, 0.0061, 0.0099, 0.0027, 0.0008, 0.0057, 0.0021, 0.0066, 0.0019, 0.0041, 0.0058, 0.0018, 0.0069, 0.0043, 0.0034, 0.0067, 0.0056, 0.0014, 0.0034, 0.0022, 0.0019, 0.0039, 0.0053, 0.0034, 0.0046, 0.0048, 0.0044, 0.0096, 0.0055, 0.0047, 0.0042, 0.009, 0.0038, 0.003, 0.007, 0.003, 0.0113, 0.0032, 0.0042, 0.0035, 0.0034, 0.0068, 0.0027, 0.0042, 0.0035, 0.0067, 0.0058, 0.0051, 0.0041, 0.0043, 0.0039, 0.0045, 0.004, 0.0077, 0.0086, 0.0097, 0.0038, 0.0059, 0.0049, 0.0061, 0.0053, 0.0005, 0.0025, 0.0068, 0.0048, 0.0057, 0.0058, 0.0046, 0.0031, 0.0087, 0.003, 0.0068, 0.0063, 0.0063, 0.0062, 0.01, 0.0091, 0.0154, 0.0051, 0.0063, 0.0051, 0.004, 0.0055, 0.0056, 0.0102, 0.0084, 0.0047, 0.0056, 0.0048, 0.0082, 0.0007, 0.0094, 0.0041, 0.0066, 0.0032, 0.0025, 0.0041, 0.0045, 0.0079, 0.0037, 0.0042, 0.0061, 0.0044, 0.005, 0.0037, 0.0022, 0.0078, 0.0066, 0.008, 0.0054, 0.0057, 0.0054, 0.0074, 0.0087, 0.0044, 0.005, 0.0042, 0.0033, 0.0077, 0.0036, 0.004, 0.0007, 0.0065, 0.0049, 0.0051, 0.0039, 0.0086, 0.0042, 0.0029, 0.0039, 0.0061, 0.012, 0.0066, 0.007, 0.0051, 0.0046, 0.0054, 0.0022, 0.0026, 0.0052, 0.0015, 0.0074, 0.0077, 0.0013, 0.0065, 0.0058, 0.0046, 0.004, 0.0034, 0.0041, 0.0079, 0.0028, 0.0049, 0.0104, 0.0033, 0.0038, 0.005, 0.007, 0.0041, 0.0021, 0.0073, 0.0088, 0.0037, 0.0017, 0.0068, 0.0087, 0.011, 0.005, 0.0024, 0.0081, 0.0071, 0.0093, 0.0076, 0.0038, 0.0041, 0.0067, 0.0062, 0.0084, 0.0089, 0.0035, 0.0018, 0.0055, 0.0034, 0.0058, 0.0044, 0.0048, 0.0035, 0.0056, 0.0045, 0.005, 0.0023, 0.001, 0.0044, 0.0036, 0.0022, 0.0033, 0.0042, 0.0064, 0.0053, 0.0053, 0.0017, 0.0041, 0.0024, 0.0063, 0.0035, 0.0063, 0.0015, 0.0039, 0.0009, 0.005, 0.0026, 0.0024, 0.0028, 0.0037, 0.0044, 0.0039, 0.0024, 0.0033, 0.003, 0.0087, 0.0077, 0.001, 0.0043, 0.0038, 0.0058, 0.0021, 0.0039, 0.0018, 0.0039, 0.0028, 0.0046, 0.0049, 0.0025, 0.0032, 0.0052, 0.0067, 0.005, 0.003, 0.0027, 0.0038, 0.0026, 0.0058, 0.0018, 0.0031, 0.0043, 0.0011, 0.0027, 0.0066, 0.0045, 0.0028, 0.0034, 0.0033, 0.0023, 0.0032, 0.0046, 0.0022, 0.0036, 0.0035, 0.0046, 0.006, 0.0022, 0.0027, 0.0055, 0.0052, 0.0038, 0.0041, 0.0121, 0.0024, 0.0033, 0.0, 0.0055, 0.0027, 0.0046, 0.0025, 0.0045, 0.0061, 0.0017, 0.0055, 0.0043, 0.0036, 0.002, 0.0041, 0.0005, 0.0026, 0.0033, 0.0105, 0.0046, 0.0022, 0.0026, 0.0025, 0.0072, 0.0034, 0.0015, 0.0066, 0.0019, 0.0036, 0.0055, 0.0031, 0.0068, 0.0061, 0.0059, 0.0042, 0.002, 0.0055, 0.0093, 0.0019, 0.0028, 0.0026, 0.0036, 0.0045, 0.0034, 0.0023, 0.0064, 0.0059, 0.0036, 0.0053, 0.0066, 0.0065, 0.004, 0.006, 0.0008, 0.0022, 0.0054, 0.0026, 0.0021, 0.003, 0.0031, 0.0054, 0.0016, 0.0037, 0.0029, 0.0036, 0.0022, 0.0039, 0.0016, 0.0035, 0.0038, 0.0062, 0.0011, 0.0073, 0.0059, 0.0027, 0.0053, 0.0022, 0.0013, 0.0042, 0.0015, 0.0069, 0.0072, 0.0005, 0.0046, 0.0024, 0.0039, 0.0023, 0.0022, 0.0033, 0.0022, 0.0043, 0.0038, 0.008, 0.0032, 0.0014, 0.0032, 0.0061, 0.0064, 0.0027, 0.0035, 0.001, 0.0005, 0.0047, 0.0044, 0.0023, 0.0021, 0.0057, 0.0008, 0.0031, 0.0017, 0.0044, 0.0019, 0.0038, 0.0011, 0.0008, 0.0068, 0.0017, 0.0017, 0.0011, 0.0023, 0.0039, 0.0012, 0.0022, 0.0062, 0.0024, 0.0008, 0.0036, 0.0019, 0.0012, 0.0054, 0.0007, 0.0009, 0.0018, 0.0019, 0.0037, 0.0018, 0.0005, 0.0047, 0.0012, 0.0007, 0.0054, 0.0046, 0.0032, 0.0014, 0.0042, 0.0038, 0.0029, 0.002, 0.0027, 0.0037, 0.0024, 0.0059, 0.0032, 0.0015, 0.0012, 0.0049, 0.0047, 0.0047, 0.0029, 0.0029, 0.0052, 0.0023, 0.0042, 0.0026, 0.0039, 0.0041, 0.0045, 0.0031, 0.001, 0.0035, 0.0013, 0.0033, 0.0028, 0.0027, 0.0048, 0.0084, 0.0018, 0.0039, 0.0019, 0.0047, 0.0031, 0.0057, 0.0001, 0.003, 0.0016, 0.0032, 0.005, 0.003, 0.0035, 0.0018, 0.0036, 0.0063, 0.0002, 0.0038, 0.0041, 0.0023, 0.0037, 0.0021, 0.0024, 0.0053, 0.003, 0.0018, 0.0016, 0.0043, 0.0047, 0.0024, 0.0036, 0.0024, 0.0026, 0.0039, 0.0009, 0.0017, 0.0013, 0.0017, 0.0021, 0.0009, 0.0003, 0.0037, 0.0029, 0.0007, 0.0032, 0.0003, 0.0039, 0.003, 0.0028, 0.0039, 0.0022, 0.0032, 0.0012, 0.0058, 0.0031, 0.0019, 0.0031, 0.0008, 0.0004, 0.0012, 0.0095, 0.0017, 0.0041, 0.0035, 0.0025, 0.0021, 0.002, 0.003, 0.0023, 0.0022, 0.0033, 0.0032, 0.0034, 0.0012, 0.0034, 0.0053, 0.0002, 0.0008, 0.0012, 0.0029, 0.0032, 0.0038, 0.0032, 0.0028, 0.0037, 0.0033, 0.0009, 0.0039, 0.0032, 0.0065, 0.0084, 0.0061, 0.0025, 0.0021, 0.0032, 0.0034, 0.0019, 0.002, 0.003, 0.0022, 0.0008, 0.0042, 0.0029, 0.0032, 0.0042, 0.0007, 0.0016, 0.0031, 0.0017, 0.0033, 0.0007, 0.0007, 0.0064, 0.0013, 0.0019, 0.0009, 0.0038, 0.0024, 0.0039, 0.001, 0.0023, 0.0023, 0.0004, 0.0033, 0.002, 0.0012, 0.0018, 0.0039, 0.0043, 0.0035, 0.0027, 0.0013, 0.0016, 0.0031, 0.0044, 0.0013, 0.0039, 0.0033, 0.0046, 0.0016, 0.0042, 0.0005, 0.001, 0.0013, 0.003, 0.0028, 0.005, 0.0046, 0.003, 0.0022, 0.0038, 0.0027, 0.0046, 0.0006, 0.0025, 0.0023, 0.0006, 0.0038, 0.001, 0.0039, 0.0029, 0.0049, 0.0026, 0.004, 0.0012, 0.0, 0.0007, 0.0024, 0.0016, 0.0017, 0.0027, 0.0036, 0.0017, 0.0009, 0.0008, 0.0009, 0.0013, 0.003, 0.0016, 0.0033, 0.0024, 0.0021, 0.0021, 0.0025, 0.0016, 0.0009, 0.0025, 0.0012, 0.0046, 0.0019, 0.0026, 0.0066, 0.0026, 0.0003, 0.0019, 0.0005, 0.0006, 0.004, 0.0035, 0.0019, 0.001, 0.0031, 0.0035, 0.0015, 0.0015, 0.0042, 0.0035, 0.0043, 0.0012, 0.0016, 0.0031, 0.0016, 0.0052, 0.0014, 0.002, 0.0017, 0.001, 0.0032, 0.001, 0.0041, 0.0026, 0.0012, 0.0011, 0.0015, 0.0004, 0.0016, 0.0003, 0.0013, 0.0045, 0.0019, 0.006, 0.0027, 0.001, 0.0017, 0.0049, 0.0022, 0.002, 0.005, 0.0012, 0.0015, 0.0015, 0.0015, 0.0008, 0.0033, 0.0031, 0.0031, 0.0032, 0.0008, 0.0062, 0.0034, 0.0003, 0.0019, 0.0009, 0.0005, 0.0031, 0.0002, 0.0013, 0.0021, 0.0013, 0.0024, 0.0016, 0.0013, 0.0022, 0.0022, 0.0013, 0.0009, 0.0022, 0.001, 0.0013, 0.0035, 0.0008, 0.0064, 0.0006, 0.0024, 0.0008, 0.0021, 0.0001, 0.0028, 0.0021, 0.0045, 0.0052, 0.003, 0.0017, 0.0026, 0.0035, 0.001, 0.0035, 0.0007, 0.0019, 0.0013, 0.0012, 0.0012, 0.0009, 0.0011, 0.0013, 0.0014, 0.0015, 0.0031, 0.0014, 0.001, 0.0036, 0.0011, 0.0034, 0.0005, 0.0019, 0.0007, 0.0028, 0.001, 0.0022, 0.0012, 0.0046, 0.0018, 0.0018, 0.0032, 0.0002, 0.0049, 0.0023, 0.0001, 0.0058, 0.0001, 0.0008, 0.0028, 0.0027, 0.0007, 0.0026, 0.0022, 0.0016, 0.0038, 0.0007, 0.0031, 0.0003, 0.0024, 0.0042, 0.0025, 0.0021, 0.0016, 0.0018, 0.0002, 0.0013, 0.0009, 0.0033, 0.0008, 0.0004, 0.0017, 0.0028, 0.0005, 0.004, 0.0009, 0.0021, 0.0025, 0.0053, 0.0045, 0.0019, 0.0013, 0.0017, 0.0007, 0.0021, 0.001, 0.0007, 0.0001, 0.0028, 0.0025, 0.0005, 0.0012, 0.0012, 0.0032, 0.0012, 0.004, 0.0012, 0.003, 0.0039, 0.0018, 0.0023, 0.0012, 0.0024, 0.0015, 0.0013, 0.0008, 0.0015, 0.0009, 0.002, 0.0013, 0.0001, 0.0013, 0.0009, 0.0004, 0.0006, 0.0028, 0.0012, 0.0026, 0.0043, 0.0019, 0.0008, 0.0031, 0.0011, 0.0003, 0.0015, 0.0014, 0.0019, 0.0022, 0.0034, 0.0012, 0.0024, 0.0007, 0.0009, 0.0008, 0.0002, 0.0024, 0.0024, 0.0009, 0.0015, 0.0026, 0.0014, 0.0008, 0.0039, 0.0075, 0.0018, 0.0017, 0.0004, 0.001, 0.0017, 0.0034, 0.0017, 0.0119, 0.0032, 0.0013, 0.0008, 0.0028, 0.0023, 0.0005, 0.0032, 0.0014, 0.0034, 0.0019, 0.0008, 0.0025, 0.0006, 0.0004, 0.003, 0.001, 0.0012, 0.0016, 0.0, 0.0026, 0.001, 0.0018, 0.0015, 0.0006, 0.0001, 0.0011, 0.0008, 0.0, 0.0007, 0.0022, 0.0026, 0.0024, 0.0016, 0.0034, 0.0011, 0.0023, 0.0046, 0.0019, 0.0034, 0.0032, 0.0003, 0.0012, 0.0005, 0.001, 0.0015, 0.0002, 0.001, 0.0051, 0.002, 0.001, 0.0007, 0.0024, 0.0014, 0.0011, 0.0026, 0.0011, 0.0021, 0.005, 0.0003, 0.002, 0.0013, 0.0048, 0.003, 0.0017, 0.0025, 0.0, 0.0008, 0.0019, 0.0008, 0.0005, 0.002, 0.0024, 0.0015, 0.0018, 0.0017, 0.0021, 0.0033, 0.0008, 0.0014, 0.0014, 0.0006, 0.0017, 0.0026, 0.0037, 0.0015, 0.0004, 0.003, 0.0028, 0.0022, 0.0014, 0.001, 0.0003, 0.0026, 0.0027, 0.0015, 0.0005, 0.0004, 0.0024, 0.0, 0.0013, 0.0021, 0.0005, 0.0021, 0.0031, 0.0013, 0.0006, 0.001, 0.0026, 0.0003, 0.0011, 0.0015, 0.0013, 0.004, 0.0021, 0.0009, 0.0005, 0.0036, 0.0013, 0.0016, 0.001, 0.0028, 0.0008, 0.0021, 0.0017, 0.0016, 0.0001, 0.0025, 0.0005, 0.0001, 0.0027, 0.0012, 0.0046, 0.0021, 0.0017, 0.0009, 0.0029, 0.0013, 0.0019, 0.0008, 0.0022, 0.0006, 0.001, 0.0005, 0.0013, 0.0001, 0.0028, 0.0014, 0.0018, 0.0018, 0.0039, 0.0007, 0.0015, 0.0035, 0.0015, 0.0003, 0.0023, 0.0037, 0.001, 0.0006, 0.0021, 0.0005, 0.0005, 0.0018, 0.0014, 0.0011, 0.0021, 0.0023, 0.003, 0.0012, 0.0029, 0.0015, 0.0021, 0.0021, 0.003, 0.0006, 0.0003, 0.0039, 0.0018, 0.0016, 0.0018, 0.0011, 0.0014, 0.0014, 0.0018, 0.0016, 0.0038, 0.0011, 0.0001, 0.0002, 0.0018, 0.0019, 0.001, 0.0011, 0.001, 0.0007, 0.0011, 0.0013, 0.0006, 0.0029, 0.0009, 0.0017, 0.0007, 0.0018, 0.0011, 0.0017, 0.0023, 0.0022, 0.0009, 0.0006, 0.0005, 0.0028, 0.0017, 0.0004, 0.0024, 0.0011, 0.0011, 0.0018, 0.0005, 0.0005, 0.0004, 0.0033, 0.0014, 0.0013, 0.0017, 0.0013, 0.0004, 0.0015, 0.0034, 0.0007, 0.0006, 0.0013, 0.0044, 0.0009, 0.0006, 0.0027, 0.0007, 0.0003, 0.0004, 0.0005, 0.0012, 0.0009, 0.0004, 0.0011, 0.0007, 0.0007, 0.0005, 0.0029, 0.0009, 0.0015, 0.0011, 0.0011, 0.0001, 0.0002, 0.0012, 0.0016, 0.0003, 0.0009, 0.0012, 0.0012, 0.0001, 0.0004, 0.0012, 0.0006, 0.001, 0.0003, 0.0, 0.001, 0.0013, 0.0014, 0.0038, 0.0004, 0.0008, 0.0008, 0.0012, 0.0017, 0.0008, 0.0006, 0.0009, 0.0029, 0.0022, 0.0011, 0.0001, 0.0018, 0.0009, 0.0002, 0.0002, 0.0012, 0.0011, 0.0004, 0.0013, 0.0007, 0.0008, 0.0017, 0.0008, 0.0014, 0.0006, 0.0015, 0.0012, 0.0001, 0.0013, 0.0003, 0.0028, 0.0005, 0.001, 0.001, 0.0023, 0.0003, 0.0004, 0.0016, 0.0007, 0.0001, 0.0023, 0.0037, 0.001, 0.0007, 0.0007, 0.0023, 0.0001, 0.0005, 0.0013, 0.0005, 0.0048, 0.001, 0.0012, 0.0024, 0.0013, 0.0002, 0.001, 0.0003, 0.0004, 0.001, 0.0012, 0.0001, 0.0009, 0.0031, 0.0005, 0.0009, 0.0005, 0.0021, 0.0005, 0.0004, 0.0, 0.0002, 0.0004, 0.0008, 0.0009, 0.0014, 0.001, 0.0024, 0.0016, 0.0031, 0.0011, 0.0, 0.0002, 0.0017, 0.0002, 0.0033, 0.0021, 0.0006, 0.0008, 0.0008, 0.0007, 0.0008, 0.0007, 0.0007, 0.0, 0.0025, 0.0003, 0.0005, 0.0015, 0.0004, 0.0019, 0.0008, 0.0008, 0.0026, 0.0014, 0.0003, 0.001, 0.0005, 0.0021, 0.0007, 0.0024, 0.0007, 0.0023, 0.0003, 0.0003, 0.0004, 0.0007, 0.0017, 0.0023, 0.0014, 0.0006, 0.0021, 0.0007, 0.0012, 0.0008, 0.0003, 0.0022, 0.003, 0.0001, 0.0004, 0.0024, 0.0005, 0.0014, 0.0006, 0.001, 0.002, 0.0053, 0.0007, 0.0018, 0.0036, 0.0003, 0.0017, 0.0003, 0.0012, 0.0, 0.0006, 0.0001, 0.0023, 0.0004, 0.0006, 0.0004, 0.0005, 0.0006, 0.0001, 0.0024, 0.002, 0.0001, 0.0013, 0.0002, 0.0003, 0.0001, 0.0014, 0.0004, 0.0016, 0.0017, 0.0014, 0.0022, 0.0022, 0.0008, 0.0016, 0.0006, 0.0006, 0.0002, 0.0, 0.0014, 0.0023, 0.0009, 0.002, 0.0035, 0.0012, 0.0, 0.0021, 0.0004, 0.0002, 0.0017, 0.0007, 0.0001, 0.0008, 0.0005, 0.0004, 0.0003, 0.0002, 0.0002, 0.0007, 0.0019, 0.0009, 0.0018, 0.0008, 0.0008, 0.0001, 0.0, 0.0011, 0.0001, 0.0006, 0.0023, 0.0004, 0.0006, 0.001, 0.0014, 0.0002, 0.0004, 0.0032, 0.0023, 0.0002, 0.0003, 0.0015, 0.0004, 0.0013, 0.0018, 0.0001, 0.0028, 0.0003, 0.0018, 0.0004, 0.0006, 0.0011, 0.0003, 0.0011, 0.0014, 0.0005, 0.0011, 0.0001, 0.0, 0.0003, 0.0009, 0.0021, 0.0013, 0.0011, 0.0015, 0.0014, 0.0011, 0.0, 0.0003, 0.0002, 0.0005, 0.0007, 0.0001, 0.0004, 0.0014, 0.0005, 0.001, 0.0006, 0.0013, 0.0004, 0.0009, 0.0014, 0.0016, 0.0001, 0.0014, 0.0025, 0.0001, 0.0007, 0.0007, 0.0002, 0.0002, 0.0006, 0.0004, 0.0001, 0.0009, 0.0028, 0.0006, 0.0012, 0.0003, 0.0015, 0.0002, 0.0005, 0.0007, 0.0009, 0.0007, 0.0002, 0.0023, 0.0005, 0.0024, 0.0017, 0.0016, 0.0023, 0.0004, 0.0006, 0.0015, 0.0017, 0.0027, 0.0005, 0.0019, 0.0011, 0.0005, 0.001, 0.0004, 0.0023, 0.0002, 0.0008, 0.0011, 0.0019, 0.0, 0.0016, 0.0, 0.0027, 0.001, 0.0005, 0.0003, 0.001, 0.0005, 0.0007, 0.0005, 0.0003, 0.0006, 0.0006, 0.0013, 0.0003, 0.0011, 0.0002, 0.0009, 0.0002, 0.0013, 0.0001, 0.0002, 0.0009, 0.0016, 0.0026, 0.0001, 0.0006, 0.0004, 0.0019, 0.0011, 0.0017, 0.0011, 0.0019, 0.0015, 0.0001, 0.0029, 0.0011, 0.0002, 0.0012, 0.0023, 0.0001, 0.0053, 0.0008, 0.0027, 0.0002, 0.0005, 0.0, 0.0004, 0.0048, 0.0006, 0.0011, 0.0004, 0.0013, 0.0003, 0.0026, 0.0006, 0.0028, 0.0028, 0.0018, 0.0004, 0.0006, 0.0012, 0.0011, 0.0, 0.0006, 0.0022, 0.0008, 0.0013, 0.0002, 0.0006, 0.0007, 0.0017, 0.003, 0.0023, 0.002, 0.0002, 0.0009, 0.0014, 0.0009, 0.0001, 0.0034, 0.0004, 0.0007, 0.001, 0.0009, 0.0011, 0.0024, 0.001, 0.0009, 0.0017, 0.0004, 0.0005, 0.0006, 0.0011, 0.0, 0.0014, 0.0016, 0.0001, 0.0031, 0.0008, 0.0003, 0.0002, 0.0015, 0.0011, 0.001, 0.0007, 0.0022, 0.0027, 0.0004, 0.0002, 0.0004, 0.0, 0.0003, 0.0014, 0.0015, 0.0002, 0.0, 0.0002, 0.0, 0.0011, 0.0003, 0.0001, 0.0008, 0.0006, 0.0002, 0.0019, 0.0013, 0.0001, 0.0016, 0.001, 0.0001, 0.0015, 0.0004, 0.0006, 0.003, 0.0003, 0.0016, 0.0008, 0.0003, 0.0021, 0.0008, 0.0003, 0.0004, 0.0006, 0.0015, 0.0013, 0.0004, 0.0007, 0.001, 0.0011, 0.0003, 0.0003, 0.0013, 0.0026, 0.0009, 0.0002, 0.0008, 0.0009, 0.0005, 0.0003, 0.0005, 0.0004, 0.0006, 0.0015, 0.0007, 0.0001, 0.0003, 0.0006, 0.0, 0.0002, 0.0006, 0.0008, 0.0014, 0.0002, 0.0004, 0.0003, 0.0001, 0.0015, 0.0008, 0.0021, 0.0014, 0.0002, 0.0, 0.004, 0.0014, 0.0002, 0.0003, 0.0003, 0.001, 0.0004, 0.001, 0.0007, 0.0014, 0.0009, 0.0021, 0.0019, 0.0012, 0.0008, 0.0001, 0.0, 0.0003, 0.0015, 0.0012, 0.0005, 0.0003, 0.004, 0.0, 0.0, 0.0007, 0.0001, 0.0, 0.0009, 0.0007, 0.0, 0.0012, 0.0013, 0.0005, 0.0004, 0.0005, 0.0011, 0.0018, 0.0, 0.001, 0.0005, 0.0008, 0.0007, 0.0006, 0.0, 0.001, 0.0014, 0.0034, 0.0004, 0.0003, 0.0029, 0.0003, 0.0006, 0.001, 0.0003, 0.001, 0.0002, 0.0008, 0.0005, 0.0005, 0.0005, 0.0004, 0.0013, 0.001, 0.0005, 0.0009, 0.0012, 0.0001, 0.0004, 0.0, 0.0009, 0.0001, 0.001, 0.0003, 0.0001, 0.0011, 0.0001, 0.0025, 0.0003, 0.0006, 0.0005, 0.0022, 0.0004, 0.0001, 0.0013, 0.0008, 0.0005, 0.0003, 0.0032, 0.0008, 0.0, 0.0, 0.0015, 0.0014, 0.0002, 0.0002, 0.0, 0.0014, 0.0001, 0.0003, 0.0013, 0.0007, 0.0013, 0.0013, 0.0008, 0.0, 0.0007, 0.0008, 0.0, 0.0004, 0.0004, 0.0001, 0.001, 0.001, 0.0002, 0.0, 0.0, 0.0018, 0.0005, 0.0003, 0.0001, 0.0014, 0.0003, 0.0, 0.0003, 0.0004, 0.0004, 0.0004, 0.0009, 0.0003, 0.0004, 0.0002, 0.0008, 0.0022, 0.0013, 0.0037, 0.0015, 0.0, 0.0007, 0.0008, 0.0003, 0.0018, 0.0006, 0.0006, 0.0, 0.0004, 0.0012, 0.0003, 0.001, 0.0005, 0.0002, 0.0011, 0.0004, 0.0028, 0.0007, 0.0, 0.0008, 0.0003, 0.0005, 0.0002, 0.001, 0.0006, 0.0002, 0.0012, 0.0004, 0.0012, 0.0004, 0.0002, 0.001, 0.0007, 0.0004, 0.0003, 0.0002, 0.0006, 0.0009, 0.0004, 0.0006, 0.0, 0.0015, 0.0008, 0.0006, 0.0004, 0.0004, 0.0005, 0.0003, 0.0002, 0.0006, 0.0005, 0.0029, 0.0003, 0.0015, 0.0002, 0.0, 0.0017, 0.0, 0.0007, 0.0042, 0.0011, 0.0, 0.0001, 0.0005, 0.0001, 0.0011, 0.0003, 0.0012, 0.0, 0.0001, 0.001, 0.0003, 0.0014, 0.0011, 0.0005, 0.0006, 0.0001, 0.0005, 0.0022, 0.0006, 0.001, 0.0019, 0.0015, 0.0001, 0.001, 0.0011, 0.0005, 0.0009, 0.0, 0.0002, 0.0001, 0.0014, 0.0006, 0.0003, 0.0023, 0.0006, 0.0, 0.0001, 0.0005, 0.0, 0.0007, 0.001, 0.0009, 0.0007, 0.0011, 0.0004, 0.0005, 0.0003, 0.0005, 0.0012, 0.0013, 0.0004, 0.0001, 0.0, 0.0007, 0.0003, 0.0005, 0.0017, 0.001, 0.0014, 0.0003, 0.0007, 0.0003, 0.0005, 0.0018, 0.0005, 0.0004, 0.0005, 0.0028, 0.0037, 0.0001, 0.0014, 0.0003, 0.001, 0.0009, 0.0012, 0.0008, 0.0007, 0.0009, 0.0002, 0.0038, 0.0003, 0.0003, 0.001, 0.0002, 0.0, 0.0002, 0.0, 0.001, 0.0007, 0.0004, 0.0, 0.0, 0.0002, 0.002, 0.0014, 0.0004, 0.002, 0.0, 0.0, 0.0013, 0.0004, 0.0003, 0.0, 0.0003, 0.0001, 0.0, 0.0001, 0.0012, 0.0003, 0.0002, 0.0001, 0.0002, 0.0002, 0.0003, 0.0005, 0.0, 0.0005, 0.0003, 0.0, 0.0001, 0.0001, 0.0002, 0.0007, 0.0003, 0.0007, 0.0004, 0.0004, 0.0004, 0.0002, 0.0027, 0.0011, 0.0012, 0.0, 0.0004, 0.0021, 0.0007, 0.0, 0.0006, 0.0004, 0.0002, 0.0002, 0.0001, 0.0003, 0.0008, 0.0, 0.0, 0.0004, 0.0002, 0.0, 0.0002, 0.0001, 0.0, 0.0001, 0.0018, 0.0006, 0.0002, 0.0001, 0.0002, 0.0012, 0.0003, 0.0009, 0.0007, 0.0003, 0.0001, 0.0, 0.0, 0.0005, 0.0011, 0.0003, 0.0, 0.0, 0.0002, 0.0008, 0.0006, 0.0009, 0.0002, 0.0001, 0.0008, 0.0002, 0.0004, 0.0006, 0.0003, 0.0001, 0.0001, 0.0008, 0.0005, 0.0021, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0004, 0.0005, 0.001, 0.0002, 0.0, 0.0002, 0.0014, 0.0012, 0.0012, 0.0004, 0.0014, 0.0, 0.0001, 0.0, 0.0009, 0.0003, 0.0001, 0.0001, 0.0001, 0.0009, 0.0004, 0.0005, 0.0005, 0.0002, 0.0001, 0.0004, 0.0, 0.0004, 0.0001, 0.0014, 0.0001, 0.0006, 0.0008, 0.0002, 0.001, 0.0003, 0.0023, 0.0009, 0.0002, 0.0002, 0.0007, 0.0004, 0.0, 0.0013, 0.0004, 0.0004, 0.0002, 0.0005, 0.0, 0.0002, 0.0011, 0.0022, 0.0003, 0.0004, 0.0002, 0.0004, 0.0011, 0.0001, 0.0015, 0.0003, 0.0002, 0.0026, 0.0005, 0.0001, 0.0001, 0.0007, 0.0, 0.0014, 0.0, 0.0005, 0.0002, 0.0001, 0.0001, 0.0003, 0.0003, 0.0004, 0.0009, 0.0001, 0.0001, 0.0008, 0.0001, 0.0001, 0.0004, 0.0009, 0.0, 0.0001, 0.0003, 0.0014, 0.0001, 0.0004, 0.0015, 0.0006, 0.0013, 0.0002, 0.0002, 0.0008, 0.0, 0.0018, 0.0001, 0.0006, 0.0002, 0.0002, 0.0002, 0.0009, 0.0, 0.0001, 0.0014, 0.0, 0.0004, 0.0004, 0.0008, 0.0003, 0.0, 0.0, 0.0001, 0.0001, 0.0011, 0.0001, 0.0, 0.0001, 0.0003, 0.0004, 0.0003, 0.0002, 0.0002, 0.0003, 0.0008, 0.0006, 0.0022, 0.0001, 0.0002, 0.0001, 0.0004, 0.0001, 0.0011, 0.0002, 0.0001, 0.0, 0.0005, 0.0001, 0.0008, 0.0014, 0.0002, 0.0, 0.0007, 0.0, 0.0002, 0.0, 0.0007, 0.0002, 0.0002, 0.0, 0.0, 0.0003, 0.0009, 0.0004, 0.0003, 0.0, 0.0005, 0.0003, 0.001, 0.0003, 0.0004, 0.0, 0.0016, 0.001, 0.0003, 0.0002, 0.0007, 0.0003, 0.0006, 0.0015, 0.0015, 0.0003, 0.0, 0.0004, 0.0002, 0.0002, 0.0005, 0.0004, 0.0004, 0.0, 0.0001, 0.0002, 0.0002, 0.0004, 0.0014, 0.0006, 0.0003, 0.0, 0.0009, 0.0, 0.0, 0.0, 0.0011, 0.001, 0.0001, 0.0006, 0.0008, 0.0002, 0.0003, 0.0001, 0.0, 0.0003, 0.0005, 0.0, 0.0001, 0.0004, 0.0008, 0.0011, 0.0004, 0.0002, 0.0004, 0.0001, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0003, 0.0003, 0.0003, 0.0017, 0.0004, 0.0, 0.0019, 0.0001, 0.0002, 0.0001, 0.001, 0.003, 0.0005, 0.0, 0.0, 0.0016, 0.0005, 0.0, 0.0001, 0.0001, 0.0002, 0.0, 0.0001, 0.0034, 0.0007, 0.0015, 0.0004, 0.0001, 0.0006, 0.0004, 0.0003, 0.0001, 0.0, 0.0008, 0.0011, 0.0002, 0.0003, 0.0, 0.0002, 0.0007, 0.0, 0.0003, 0.0004, 0.0003, 0.0002, 0.0004, 0.0001, 0.0013, 0.0001, 0.0004, 0.0007, 0.0, 0.0002, 0.0033, 0.0012, 0.0001, 0.0016, 0.0005, 0.0008, 0.0006, 0.0014, 0.0002, 0.0, 0.0002, 0.002, 0.0, 0.0, 0.0008, 0.0004, 0.0007, 0.0003, 0.0018, 0.0001, 0.0, 0.0005, 0.0001, 0.0001, 0.0002, 0.0001, 0.0, 0.0008, 0.004, 0.0023, 0.0002, 0.0011, 0.0005, 0.0002, 0.0019, 0.0002, 0.0019, 0.0, 0.0, 0.0001, 0.0011, 0.0001, 0.0004, 0.0002, 0.0001, 0.0014, 0.0001, 0.0005, 0.0001, 0.0002, 0.0024, 0.0008, 0.0012, 0.0006, 0.0001, 0.0004, 0.0014, 0.0014, 0.0003, 0.0002, 0.0, 0.0, 0.0005, 0.0007, 0.0001, 0.0009, 0.0, 0.0013, 0.0001, 0.0007, 0.0, 0.0001, 0.0006, 0.0001, 0.0001, 0.0, 0.0004, 0.0019, 0.002, 0.0002, 0.0004, 0.0013, 0.0002, 0.0001, 0.0, 0.0008, 0.0001, 0.0003, 0.0012, 0.0004, 0.0002, 0.0002, 0.0002, 0.0006, 0.0001, 0.0004, 0.0014, 0.0001, 0.0006, 0.0001, 0.0012, 0.0006, 0.0002, 0.0, 0.0004, 0.0, 0.0008, 0.0002, 0.0003, 0.0017, 0.0002, 0.0004, 0.0004, 0.0001, 0.0, 0.001, 0.001, 0.0008, 0.0004, 0.0001, 0.0015, 0.0011, 0.001, 0.0004, 0.0004, 0.0, 0.0003, 0.0018, 0.0004, 0.0006, 0.0001, 0.0, 0.0003, 0.0008, 0.0, 0.0007, 0.0005, 0.0011, 0.0002, 0.0001, 0.0006, 0.0, 0.0, 0.0008, 0.0008, 0.0004, 0.0006, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0003, 0.0002, 0.0006, 0.0002, 0.0, 0.0013, 0.0002, 0.0007, 0.0004, 0.0006, 0.0001, 0.0001, 0.0011, 0.0, 0.0003, 0.0004, 0.0001, 0.0007, 0.0, 0.0012, 0.0002, 0.0002, 0.0002, 0.0004, 0.0011, 0.0002, 0.0006, 0.0004, 0.0008, 0.0002, 0.0003, 0.0, 0.0, 0.0004, 0.0029, 0.0, 0.0002, 0.0002, 0.0004, 0.0007, 0.0001, 0.0001, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0012, 0.0007, 0.0001, 0.0001, 0.0007, 0.0001, 0.0002, 0.0005, 0.0006, 0.0, 0.0, 0.0001, 0.0002, 0.0003, 0.0012, 0.0012, 0.0001, 0.0006, 0.0, 0.0006, 0.0002, 0.0008, 0.0001, 0.0001, 0.0, 0.0, 0.0002, 0.0001, 0.0017, 0.0001, 0.0002, 0.0, 0.0004, 0.0003, 0.0013, 0.0004, 0.0, 0.0, 0.0, 0.0003, 0.0001, 0.0001, 0.002, 0.0002, 0.0003, 0.0029, 0.0003, 0.0001, 0.0, 0.0003, 0.0005, 0.0003, 0.0006, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0004, 0.0026, 0.0008, 0.0003, 0.0004, 0.0001, 0.0007, 0.0, 0.0002, 0.0001, 0.0, 0.0001, 0.0002, 0.0001, 0.0004, 0.0004, 0.0012, 0.0002, 0.0, 0.0001, 0.0006, 0.0002, 0.0, 0.0004, 0.0, 0.0002, 0.0004, 0.0, 0.0, 0.0005, 0.0008, 0.0, 0.0005, 0.0005, 0.0001, 0.0, 0.0, 0.0002, 0.0013, 0.0002, 0.0003, 0.0, 0.0006, 0.0, 0.0001, 0.0003, 0.0007, 0.0001, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0007, 0.0, 0.0, 0.0005, 0.0, 0.0006, 0.0001, 0.0004, 0.0001, 0.0002, 0.0001, 0.0002, 0.0017, 0.0003, 0.0001, 0.0, 0.002, 0.0003, 0.0004, 0.0021, 0.0002, 0.0001, 0.0001, 0.0004, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0002, 0.0002, 0.0012, 0.0006, 0.0003, 0.0007, 0.0002, 0.0003, 0.0003, 0.0002, 0.0001, 0.0002, 0.0, 0.0001, 0.0002, 0.0002, 0.0003, 0.0, 0.0001, 0.0002, 0.0002, 0.0001, 0.0001, 0.0, 0.0, 0.0022, 0.0, 0.0002, 0.0001, 0.0003, 0.0009, 0.0, 0.0, 0.0002, 0.0007, 0.0, 0.0003, 0.0008, 0.0002, 0.0, 0.0, 0.0003, 0.0001, 0.0004, 0.0004, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0009, 0.0, 0.0002, 0.0002, 0.0001, 0.0006, 0.0004, 0.0003, 0.0, 0.0004, 0.0004, 0.0003, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0003, 0.0004, 0.0003, 0.0002, 0.0003, 0.0003, 0.0003, 0.0001, 0.0004, 0.0002, 0.0, 0.0009, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0004, 0.0008, 0.0002, 0.0, 0.0001, 0.0008, 0.0, 0.0, 0.0, 0.0, 0.0013, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0004, 0.0007, 0.0, 0.0, 0.0004, 0.0, 0.0, 0.0004, 0.0001, 0.0, 0.0001, 0.0005, 0.0, 0.0006, 0.0001, 0.0001, 0.0001, 0.0005, 0.0, 0.0005, 0.0, 0.0003, 0.0, 0.0002, 0.0006, 0.0011, 0.0011, 0.0, 0.0, 0.0015, 0.0001, 0.0009, 0.0012, 0.002, 0.0004, 0.0006, 0.0003, 0.0017, 0.0003, 0.0002, 0.0, 0.0005, 0.0002, 0.0018, 0.0001, 0.0005, 0.0008, 0.0, 0.0, 0.0, 0.0, 0.0005, 0.0005, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0002, 0.0001, 0.0001, 0.0, 0.0003, 0.0001, 0.0002, 0.0001, 0.0001, 0.0003, 0.0002, 0.0003, 0.0, 0.0001, 0.001, 0.0007, 0.0, 0.0001, 0.0021, 0.0, 0.0, 0.0001, 0.0013, 0.0, 0.0, 0.0001, 0.0008, 0.0, 0.0, 0.0007, 0.0002, 0.0003, 0.0002, 0.0001, 0.0005, 0.0007, 0.0001, 0.0018, 0.0003, 0.0001, 0.0, 0.0002, 0.0, 0.0009, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0005, 0.0, 0.0, 0.0006, 0.0005, 0.0, 0.0003, 0.0014, 0.0007, 0.0001, 0.0008, 0.0003, 0.0009, 0.0, 0.0, 0.0006, 0.0005, 0.0014, 0.0, 0.0001, 0.0, 0.0001, 0.0003, 0.0004, 0.0002, 0.0, 0.0001, 0.0003, 0.0, 0.0003, 0.0001, 0.0001, 0.0005, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0006, 0.0004, 0.0001, 0.0009, 0.0011, 0.0002, 0.0, 0.0002, 0.0001, 0.0, 0.0003, 0.0004, 0.0027, 0.0, 0.0, 0.0005, 0.0004, 0.0005, 0.0002, 0.0001, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0004, 0.0, 0.0011, 0.0004, 0.0002, 0.0, 0.0014, 0.0002, 0.0001, 0.0001, 0.0014, 0.0003, 0.0003, 0.0001, 0.0006, 0.0001, 0.0006, 0.0002, 0.0006, 0.0003, 0.003, 0.0001, 0.0005, 0.0, 0.0002, 0.0, 0.0001, 0.0001, 0.0001, 0.0001, 0.0004, 0.0008, 0.0003, 0.0, 0.0004, 0.0008, 0.0009, 0.0003, 0.0001, 0.0009, 0.0003, 0.0009, 0.0001, 0.0004, 0.0, 0.0002, 0.0, 0.0001, 0.0004, 0.0014, 0.0004, 0.0006, 0.0001, 0.0002, 0.0008, 0.0006, 0.0, 0.0, 0.0, 0.0009, 0.0, 0.0002, 0.0003, 0.0, 0.0011, 0.0002, 0.0009, 0.0001, 0.0001, 0.0001, 0.0002, 0.0, 0.0006, 0.0003, 0.0014, 0.0013, 0.0, 0.001, 0.0, 0.0003, 0.0002, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0009, 0.0, 0.0, 0.0004, 0.0003, 0.0, 0.0014, 0.0001, 0.0002, 0.0001, 0.0001, 0.0001, 0.0011, 0.0007, 0.0, 0.0002, 0.0, 0.0005, 0.001, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0002, 0.0001, 0.0017, 0.0004, 0.0, 0.0, 0.0, 0.0027, 0.0001, 0.0001, 0.0001, 0.0, 0.0004, 0.0002, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0003, 0.0002, 0.0008, 0.0001, 0.0002, 0.0001, 0.0009, 0.0012, 0.0013, 0.0, 0.0003, 0.0, 0.0001, 0.0006, 0.001, 0.0004, 0.0, 0.0006, 0.0002, 0.0004, 0.0001, 0.0003, 0.0001, 0.0007, 0.0001, 0.0, 0.0001, 0.0004, 0.0, 0.0, 0.0002, 0.0014, 0.0002, 0.0001, 0.0002, 0.0, 0.0, 0.0003, 0.0001, 0.0002, 0.0, 0.002, 0.0006, 0.0002, 0.0006, 0.0002, 0.0016, 0.0001, 0.0, 0.0002, 0.001, 0.0, 0.0003, 0.0, 0.0005, 0.0002, 0.0004, 0.0003, 0.0019, 0.0, 0.0002, 0.0009, 0.0008, 0.0, 0.0004, 0.0003, 0.0005, 0.0003, 0.0001, 0.0, 0.0004, 0.0, 0.0008, 0.0011, 0.0001, 0.0, 0.0002, 0.0014, 0.0, 0.0001, 0.0001, 0.0014, 0.0, 0.0004, 0.0009, 0.0005, 0.0, 0.0016, 0.0005, 0.0, 0.0003, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0009, 0.0007, 0.0, 0.0002, 0.0, 0.0008, 0.0, 0.0009, 0.0, 0.0004, 0.0004, 0.0, 0.0001, 0.002, 0.0003, 0.0004, 0.0003, 0.0002, 0.0, 0.0007, 0.0001, 0.0003, 0.0, 0.0004, 0.0001, 0.0003, 0.0001, 0.0002, 0.0, 0.0001, 0.0002, 0.0002, 0.0, 0.0014, 0.0001, 0.0, 0.0, 0.0, 0.0005, 0.0, 0.0, 0.0001, 0.0004, 0.0003, 0.0002, 0.0, 0.0004, 0.0003, 0.0009, 0.0, 0.0003, 0.0003, 0.0001, 0.0002, 0.0002, 0.0003, 0.0, 0.0002, 0.0004, 0.0, 0.0, 0.0002, 0.0, 0.0005, 0.0003, 0.0008, 0.0006, 0.0005, 0.0003, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0014, 0.0, 0.0001, 0.0, 0.0, 0.0005, 0.0003, 0.0002, 0.0004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0006, 0.0016, 0.0, 0.0001, 0.0, 0.0, 0.0011, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0002, 0.0, 0.0009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0002, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0002, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0007, 0.0007, 0.0002, 0.0, 0.0, 0.0009, 0.0004, 0.0002, 0.0, 0.0013, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0003, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005, 0.0001, 0.0, 0.0002, 0.0, 0.0006, 0.0004, 0.0001, 0.0, 0.0, 0.0001, 0.0004, 0.0, 0.0, 0.0003, 0.0005, 0.0, 0.0, 0.0001, 0.0005, 0.0001, 0.0, 0.0002, 0.0003, 0.0002, 0.0001, 0.0002, 0.0003, 0.0006, 0.0002, 0.0015, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0012, 0.0, 0.0, 0.0, 0.0, 0.0008, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0002, 0.0, 0.0002, 0.0001, 0.0004, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0011, 0.0, 0.0003, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0005, 0.0, 0.0004, 0.0, 0.0, 0.0001, 0.0, 0.0013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0007, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0005, 0.0, 0.0, 0.0004, 0.0, 0.0005, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0002, 0.0, 0.0001, 0.0004, 0.0, 0.0002, 0.0021, 0.0, 0.0006, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0002, 0.0, 0.001, 0.0008, 0.0005, 0.0003, 0.0, 0.0003, 0.0002, 0.0002, 0.0, 0.0016, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0001, 0.0006, 0.0002, 0.001, 0.0002, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0002, 0.0013, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0008, 0.0, 0.0001, 0.0001, 0.0012, 0.0, 0.0, 0.0, 0.0, 0.0008, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0008, 0.0, 0.0, 0.0002, 0.0002, 0.0004, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0003, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0003, 0.0, 0.0013, 0.0002, 0.0, 0.0001, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0016, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0011, 0.0001, 0.0008, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0022, 0.0, 0.0, 0.0008, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0008, 0.0001, 0.0, 0.0, 0.0002, 0.0005, 0.0, 0.0, 0.0, 0.0001, 0.0005, 0.0003, 0.0002, 0.0003, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0003, 0.0, 0.0002, 0.0, 0.001, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0006, 0.0, 0.0006, 0.0002, 0.0, 0.0, 0.0001, 0.0008, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0003, 0.0, 0.0013, 0.0, 0.0001, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0005, 0.0, 0.0, 0.0014, 0.0, 0.0, 0.0, 0.0007, 0.0, 0.0007, 0.0011, 0.0001, 0.0, 0.0004, 0.0001, 0.0, 0.0, 0.0002, 0.0003, 0.0001, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0013, 0.0, 0.0, 0.0001, 0.0, 0.0007, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0004, 0.0001, 0.0, 0.0001, 0.0, 0.0003, 0.0002, 0.0001, 0.0, 0.0001, 0.0002, 0.001, 0.001, 0.0, 0.0008, 0.0001, 0.0001, 0.0004, 0.0, 0.0, 0.0002, 0.0, 0.0002, 0.0021, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.002, 0.0, 0.0002, 0.0, 0.0003, 0.0, 0.0, 0.0002, 0.0, 0.0006, 0.0001, 0.0002, 0.0, 0.0, 0.0003, 0.0, 0.0003, 0.0001, 0.0001, 0.0, 0.0011, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0002, 0.0, 0.0002, 0.0001, 0.0, 0.0017, 0.0001, 0.0002, 0.0012, 0.0, 0.0019, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0003, 0.0001, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0003, 0.0003, 0.0, 0.0003, 0.0003, 0.0003, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0002, 0.0, 0.0005, 0.0, 0.0001, 0.0004, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0013, 0.0001, 0.0, 0.0001, 0.0001, 0.0003, 0.0, 0.0001, 0.0018, 0.0001, 0.0006, 0.0, 0.0001, 0.001, 0.0003, 0.0003, 0.0001, 0.0, 0.0001, 0.0003, 0.0002, 0.0, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0002, 0.0002, 0.0, 0.0, 0.0011, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0002, 0.0006, 0.0001, 0.0001, 0.0003, 0.0, 0.0001, 0.0009, 0.0, 0.0, 0.0009, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0002, 0.0, 0.0005, 0.0, 0.0, 0.0, 0.0002, 0.0004, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0013, 0.0001, 0.0, 0.0006, 0.0, 0.0003, 0.0001, 0.0001, 0.0002, 0.0, 0.0005, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0002, 0.0, 0.0011, 0.0013, 0.0, 0.0, 0.0011, 0.0001, 0.0, 0.0001, 0.0008, 0.0, 0.0, 0.0006, 0.0003, 0.0001, 0.0008, 0.0003, 0.0, 0.0006, 0.0, 0.0, 0.0, 0.0005, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0007, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0006, 0.0004, 0.0004, 0.0009, 0.0002, 0.0, 0.0, 0.0002, 0.0006, 0.0, 0.0002, 0.0002, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0001, 0.0002, 0.0002, 0.0011, 0.0, 0.0001, 0.0004, 0.0, 0.0001, 0.0004, 0.0, 0.0, 0.0008, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0007, 0.0003, 0.0003, 0.0, 0.0001, 0.0, 0.001, 0.0004, 0.0013, 0.0003, 0.0001, 0.0, 0.0001, 0.0, 0.001, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0003, 0.0011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0001, 0.0001, 0.0002, 0.0002, 0.0, 0.0, 0.0, 0.0006, 0.0, 0.0, 0.0, 0.0003, 0.0001, 0.0002, 0.0002, 0.0, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0011, 0.0002, 0.0, 0.0006, 0.0, 0.0, 0.0003, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0005, 0.0001, 0.0002, 0.0007, 0.0, 0.0, 0.0, 0.0006, 0.0, 0.0006, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0012, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0007, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0003, 0.0004, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0004, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0005, 0.0004, 0.0003, 0.0, 0.0001, 0.0009, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0002, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0006, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0001, 0.0006, 0.0, 0.0007, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0001, 0.0004, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0007, 0.0, 0.0001, 0.0001, 0.0002, 0.0001, 0.0008, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0006, 0.0, 0.0012, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0003, 0.0, 0.0002, 0.0004, 0.0, 0.0012, 0.0, 0.0, 0.0, 0.0001, 0.0006, 0.0, 0.0001, 0.0004, 0.0, 0.0, 0.0002, 0.0001, 0.0006, 0.0003, 0.0, 0.0009, 0.0007, 0.0, 0.0003, 0.0001, 0.0, 0.0, 0.0002, 0.0003, 0.0003, 0.0002, 0.0001, 0.0001, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0004, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0002, 0.0, 0.0012, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0005, 0.0003, 0.0006, 0.0, 0.0, 0.0003, 0.0002, 0.0011, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0006, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0006, 0.0002, 0.0, 0.0001, 0.0, 0.0004, 0.0003, 0.0001, 0.0, 0.0007, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0007, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0006, 0.0001, 0.0001, 0.0, 0.0002, 0.0002, 0.0004, 0.0, 0.0, 0.0002, 0.0006, 0.0, 0.0014, 0.0, 0.0007, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0004, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0002, 0.0, 0.0, 0.0001, 0.0003, 0.0, 0.0002, 0.0007, 0.0001, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0004, 0.0001, 0.0, 0.0007, 0.0, 0.0001, 0.0001, 0.0007, 0.0004, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0014, 0.0, 0.0007, 0.0001, 0.0, 0.0006, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0003, 0.0003, 0.0001, 0.0, 0.0, 0.0003, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0013, 0.0004, 0.0004, 0.0005, 0.0, 0.0003, 0.0, 0.0005, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0006, 0.0, 0.0004, 0.0001, 0.0, 0.0002, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0006, 0.0002, 0.0017, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0001, 0.0, 0.0, 0.0002, 0.0007, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0001, 0.0003, 0.0001, 0.0002, 0.0, 0.0001, 0.0003, 0.0004, 0.0, 0.0001, 0.0001, 0.0007, 0.0, 0.0011, 0.0, 0.0, 0.0001, 0.0003, 0.0003, 0.0004, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0002, 0.0004, 0.0002, 0.0002, 0.0, 0.0002, 0.0, 0.0019, 0.0, 0.0, 0.0006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0007, 0.0001, 0.0, 0.0, 0.0013, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0015, 0.0018, 0.0, 0.0, 0.0004, 0.0003, 0.0, 0.0002, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0005, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0003, 0.0004, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0003, 0.0001, 0.0002, 0.0, 0.0, 0.0002, 0.0001, 0.0001, 0.0014, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0004, 0.0002, 0.0008, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0004, 0.0002, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0004, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0003, 0.0, 0.0002, 0.0, 0.0002, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0003, 0.0001, 0.0001, 0.0001, 0.0001, 0.0004, 0.0001, 0.0001, 0.0003, 0.0, 0.0002, 0.0, 0.0001, 0.0005, 0.0, 0.0003, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0004, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0003, 0.0001, 0.0007, 0.0002, 0.0, 0.0, 0.0002, 0.0002, 0.0001, 0.0004, 0.0, 0.0, 0.0, 0.0005, 0.0, 0.0001, 0.0001, 0.0002, 0.0003, 0.0002, 0.0004, 0.0, 0.0004, 0.0001, 0.0006, 0.0017, 0.0001, 0.0, 0.0001, 0.0, 0.0002, 0.0001, 0.0004, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0002, 0.0002, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0001, 0.0001, 0.0002, 0.0002, 0.0, 0.0002, 0.0004, 0.0, 0.0, 0.0001, 0.0, 0.0007, 0.0001, 0.0, 0.0, 0.0004, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0008, 0.0, 0.0001, 0.0007, 0.0, 0.0006, 0.0001, 0.0001, 0.0, 0.0004, 0.0002, 0.0, 0.0004, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0013, 0.0003, 0.0, 0.0, 0.0007, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0009, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0005, 0.0, 0.0, 0.0005, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0004, 0.002, 0.0, 0.0, 0.0, 0.0002, 0.0014, 0.001, 0.0001, 0.0001, 0.0003, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0002, 0.0, 0.0002, 0.0002, 0.0004, 0.0001, 0.0, 0.0, 0.0011, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0001, 0.0009, 0.0, 0.0, 0.0006, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0001, 0.0002, 0.0, 0.0, 0.0002, 0.0002, 0.0, 0.0001, 0.0007, 0.0007, 0.0, 0.0, 0.0001, 0.0004, 0.0, 0.0018, 0.0001, 0.0011, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0003, 0.0, 0.0001, 0.0009, 0.0002, 0.0, 0.0006, 0.0, 0.0, 0.0002, 0.0015, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0004, 0.0, 0.0, 0.0001, 0.0019, 0.0003, 0.0, 0.0001, 0.0, 0.0006, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0008, 0.0005, 0.0, 0.0, 0.0012, 0.0, 0.0002, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0003, 0.0001, 0.0001, 0.0002, 0.0001, 0.0001, 0.0006, 0.0002, 0.0, 0.0, 0.0002, 0.0002, 0.0004, 0.0, 0.0011, 0.0001, 0.0, 0.0, 0.0, 0.0006, 0.0001, 0.0002, 0.0, 0.0005, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0009, 0.0004, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0001, 0.0003, 0.0001, 0.0003, 0.0002, 0.0003, 0.0, 0.0002, 0.0013, 0.0006, 0.0, 0.0008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0006, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0008, 0.0, 0.0, 0.0, 0.0001, 0.0004, 0.0, 0.0011, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.001, 0.0, 0.0, 0.0001, 0.0015, 0.0004, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0007, 0.0, 0.0, 0.0, 0.0017, 0.0, 0.0, 0.0001, 0.0003, 0.0001, 0.0005, 0.0001, 0.0002, 0.0002, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0002, 0.0013, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0006, 0.0001, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0]), probability=DenseVector([0.0, 0.0013, 0.0007, 0.001, 0.0008, 0.0011, 0.001, 0.0008, 0.0003, 0.001, 0.0015, 0.0009, 0.0003, 0.0007, 0.0007, 0.0013, 0.0009, 0.0009, 0.0011, 0.001, 0.0006, 0.0017, 0.0003, 0.0012, 0.002, 0.0005, 0.0002, 0.0011, 0.0004, 0.0013, 0.0004, 0.0008, 0.0012, 0.0004, 0.0014, 0.0009, 0.0007, 0.0013, 0.0011, 0.0003, 0.0007, 0.0004, 0.0004, 0.0008, 0.0011, 0.0007, 0.0009, 0.001, 0.0009, 0.0019, 0.0011, 0.0009, 0.0008, 0.0018, 0.0008, 0.0006, 0.0014, 0.0006, 0.0023, 0.0006, 0.0008, 0.0007, 0.0007, 0.0014, 0.0005, 0.0008, 0.0007, 0.0013, 0.0012, 0.001, 0.0008, 0.0009, 0.0008, 0.0009, 0.0008, 0.0015, 0.0017, 0.0019, 0.0008, 0.0012, 0.001, 0.0012, 0.0011, 0.0001, 0.0005, 0.0014, 0.001, 0.0011, 0.0012, 0.0009, 0.0006, 0.0017, 0.0006, 0.0014, 0.0013, 0.0013, 0.0012, 0.002, 0.0018, 0.0031, 0.001, 0.0013, 0.001, 0.0008, 0.0011, 0.0011, 0.002, 0.0017, 0.0009, 0.0011, 0.001, 0.0016, 0.0001, 0.0019, 0.0008, 0.0013, 0.0006, 0.0005, 0.0008, 0.0009, 0.0016, 0.0007, 0.0008, 0.0012, 0.0009, 0.001, 0.0007, 0.0004, 0.0016, 0.0013, 0.0016, 0.0011, 0.0011, 0.0011, 0.0015, 0.0017, 0.0009, 0.001, 0.0008, 0.0007, 0.0015, 0.0007, 0.0008, 0.0001, 0.0013, 0.001, 0.001, 0.0008, 0.0017, 0.0008, 0.0006, 0.0008, 0.0012, 0.0024, 0.0013, 0.0014, 0.001, 0.0009, 0.0011, 0.0004, 0.0005, 0.001, 0.0003, 0.0015, 0.0015, 0.0003, 0.0013, 0.0012, 0.0009, 0.0008, 0.0007, 0.0008, 0.0016, 0.0006, 0.001, 0.0021, 0.0007, 0.0008, 0.001, 0.0014, 0.0008, 0.0004, 0.0015, 0.0018, 0.0007, 0.0003, 0.0014, 0.0017, 0.0022, 0.001, 0.0005, 0.0016, 0.0014, 0.0019, 0.0015, 0.0008, 0.0008, 0.0013, 0.0012, 0.0017, 0.0018, 0.0007, 0.0004, 0.0011, 0.0007, 0.0012, 0.0009, 0.001, 0.0007, 0.0011, 0.0009, 0.001, 0.0005, 0.0002, 0.0009, 0.0007, 0.0004, 0.0007, 0.0008, 0.0013, 0.0011, 0.0011, 0.0003, 0.0008, 0.0005, 0.0013, 0.0007, 0.0013, 0.0003, 0.0008, 0.0002, 0.001, 0.0005, 0.0005, 0.0006, 0.0007, 0.0009, 0.0008, 0.0005, 0.0007, 0.0006, 0.0017, 0.0015, 0.0002, 0.0009, 0.0008, 0.0012, 0.0004, 0.0008, 0.0004, 0.0008, 0.0006, 0.0009, 0.001, 0.0005, 0.0006, 0.001, 0.0013, 0.001, 0.0006, 0.0005, 0.0008, 0.0005, 0.0012, 0.0004, 0.0006, 0.0009, 0.0002, 0.0005, 0.0013, 0.0009, 0.0006, 0.0007, 0.0007, 0.0005, 0.0006, 0.0009, 0.0004, 0.0007, 0.0007, 0.0009, 0.0012, 0.0004, 0.0005, 0.0011, 0.001, 0.0008, 0.0008, 0.0024, 0.0005, 0.0007, 0.0, 0.0011, 0.0005, 0.0009, 0.0005, 0.0009, 0.0012, 0.0003, 0.0011, 0.0009, 0.0007, 0.0004, 0.0008, 0.0001, 0.0005, 0.0007, 0.0021, 0.0009, 0.0004, 0.0005, 0.0005, 0.0014, 0.0007, 0.0003, 0.0013, 0.0004, 0.0007, 0.0011, 0.0006, 0.0014, 0.0012, 0.0012, 0.0008, 0.0004, 0.0011, 0.0019, 0.0004, 0.0006, 0.0005, 0.0007, 0.0009, 0.0007, 0.0005, 0.0013, 0.0012, 0.0007, 0.0011, 0.0013, 0.0013, 0.0008, 0.0012, 0.0002, 0.0004, 0.0011, 0.0005, 0.0004, 0.0006, 0.0006, 0.0011, 0.0003, 0.0007, 0.0006, 0.0007, 0.0004, 0.0008, 0.0003, 0.0007, 0.0008, 0.0012, 0.0002, 0.0015, 0.0012, 0.0005, 0.0011, 0.0004, 0.0003, 0.0008, 0.0003, 0.0014, 0.0014, 0.0001, 0.0009, 0.0005, 0.0008, 0.0005, 0.0004, 0.0007, 0.0004, 0.0009, 0.0008, 0.0016, 0.0006, 0.0003, 0.0006, 0.0012, 0.0013, 0.0005, 0.0007, 0.0002, 0.0001, 0.0009, 0.0009, 0.0005, 0.0004, 0.0011, 0.0002, 0.0006, 0.0003, 0.0009, 0.0004, 0.0008, 0.0002, 0.0002, 0.0014, 0.0003, 0.0003, 0.0002, 0.0005, 0.0008, 0.0002, 0.0004, 0.0012, 0.0005, 0.0002, 0.0007, 0.0004, 0.0002, 0.0011, 0.0001, 0.0002, 0.0004, 0.0004, 0.0007, 0.0004, 0.0001, 0.0009, 0.0002, 0.0001, 0.0011, 0.0009, 0.0006, 0.0003, 0.0008, 0.0008, 0.0006, 0.0004, 0.0005, 0.0007, 0.0005, 0.0012, 0.0006, 0.0003, 0.0002, 0.001, 0.0009, 0.0009, 0.0006, 0.0006, 0.001, 0.0005, 0.0008, 0.0005, 0.0008, 0.0008, 0.0009, 0.0006, 0.0002, 0.0007, 0.0003, 0.0007, 0.0006, 0.0005, 0.001, 0.0017, 0.0004, 0.0008, 0.0004, 0.0009, 0.0006, 0.0011, 0.0, 0.0006, 0.0003, 0.0006, 0.001, 0.0006, 0.0007, 0.0004, 0.0007, 0.0013, 0.0, 0.0008, 0.0008, 0.0005, 0.0007, 0.0004, 0.0005, 0.0011, 0.0006, 0.0004, 0.0003, 0.0009, 0.0009, 0.0005, 0.0007, 0.0005, 0.0005, 0.0008, 0.0002, 0.0003, 0.0003, 0.0003, 0.0004, 0.0002, 0.0001, 0.0007, 0.0006, 0.0001, 0.0006, 0.0001, 0.0008, 0.0006, 0.0006, 0.0008, 0.0004, 0.0006, 0.0002, 0.0012, 0.0006, 0.0004, 0.0006, 0.0002, 0.0001, 0.0002, 0.0019, 0.0003, 0.0008, 0.0007, 0.0005, 0.0004, 0.0004, 0.0006, 0.0005, 0.0004, 0.0007, 0.0006, 0.0007, 0.0002, 0.0007, 0.0011, 0.0, 0.0002, 0.0002, 0.0006, 0.0006, 0.0008, 0.0006, 0.0006, 0.0007, 0.0007, 0.0002, 0.0008, 0.0006, 0.0013, 0.0017, 0.0012, 0.0005, 0.0004, 0.0006, 0.0007, 0.0004, 0.0004, 0.0006, 0.0004, 0.0002, 0.0008, 0.0006, 0.0006, 0.0008, 0.0001, 0.0003, 0.0006, 0.0003, 0.0007, 0.0001, 0.0001, 0.0013, 0.0003, 0.0004, 0.0002, 0.0008, 0.0005, 0.0008, 0.0002, 0.0005, 0.0005, 0.0001, 0.0007, 0.0004, 0.0002, 0.0004, 0.0008, 0.0009, 0.0007, 0.0005, 0.0003, 0.0003, 0.0006, 0.0009, 0.0003, 0.0008, 0.0007, 0.0009, 0.0003, 0.0008, 0.0001, 0.0002, 0.0003, 0.0006, 0.0006, 0.001, 0.0009, 0.0006, 0.0004, 0.0008, 0.0005, 0.0009, 0.0001, 0.0005, 0.0005, 0.0001, 0.0008, 0.0002, 0.0008, 0.0006, 0.001, 0.0005, 0.0008, 0.0002, 0.0, 0.0001, 0.0005, 0.0003, 0.0003, 0.0005, 0.0007, 0.0003, 0.0002, 0.0002, 0.0002, 0.0003, 0.0006, 0.0003, 0.0007, 0.0005, 0.0004, 0.0004, 0.0005, 0.0003, 0.0002, 0.0005, 0.0002, 0.0009, 0.0004, 0.0005, 0.0013, 0.0005, 0.0001, 0.0004, 0.0001, 0.0001, 0.0008, 0.0007, 0.0004, 0.0002, 0.0006, 0.0007, 0.0003, 0.0003, 0.0008, 0.0007, 0.0009, 0.0002, 0.0003, 0.0006, 0.0003, 0.001, 0.0003, 0.0004, 0.0003, 0.0002, 0.0006, 0.0002, 0.0008, 0.0005, 0.0002, 0.0002, 0.0003, 0.0001, 0.0003, 0.0001, 0.0003, 0.0009, 0.0004, 0.0012, 0.0005, 0.0002, 0.0003, 0.001, 0.0004, 0.0004, 0.001, 0.0002, 0.0003, 0.0003, 0.0003, 0.0002, 0.0007, 0.0006, 0.0006, 0.0006, 0.0002, 0.0012, 0.0007, 0.0001, 0.0004, 0.0002, 0.0001, 0.0006, 0.0, 0.0003, 0.0004, 0.0003, 0.0005, 0.0003, 0.0003, 0.0004, 0.0004, 0.0003, 0.0002, 0.0004, 0.0002, 0.0003, 0.0007, 0.0002, 0.0013, 0.0001, 0.0005, 0.0002, 0.0004, 0.0, 0.0006, 0.0004, 0.0009, 0.001, 0.0006, 0.0003, 0.0005, 0.0007, 0.0002, 0.0007, 0.0001, 0.0004, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003, 0.0003, 0.0003, 0.0006, 0.0003, 0.0002, 0.0007, 0.0002, 0.0007, 0.0001, 0.0004, 0.0001, 0.0006, 0.0002, 0.0004, 0.0002, 0.0009, 0.0004, 0.0004, 0.0006, 0.0, 0.001, 0.0005, 0.0, 0.0012, 0.0, 0.0002, 0.0006, 0.0005, 0.0001, 0.0005, 0.0004, 0.0003, 0.0008, 0.0001, 0.0006, 0.0001, 0.0005, 0.0008, 0.0005, 0.0004, 0.0003, 0.0004, 0.0, 0.0003, 0.0002, 0.0007, 0.0002, 0.0001, 0.0003, 0.0006, 0.0001, 0.0008, 0.0002, 0.0004, 0.0005, 0.0011, 0.0009, 0.0004, 0.0003, 0.0003, 0.0001, 0.0004, 0.0002, 0.0001, 0.0, 0.0006, 0.0005, 0.0001, 0.0002, 0.0002, 0.0006, 0.0002, 0.0008, 0.0002, 0.0006, 0.0008, 0.0004, 0.0005, 0.0002, 0.0005, 0.0003, 0.0003, 0.0002, 0.0003, 0.0002, 0.0004, 0.0003, 0.0, 0.0003, 0.0002, 0.0001, 0.0001, 0.0006, 0.0002, 0.0005, 0.0009, 0.0004, 0.0002, 0.0006, 0.0002, 0.0001, 0.0003, 0.0003, 0.0004, 0.0004, 0.0007, 0.0002, 0.0005, 0.0001, 0.0002, 0.0002, 0.0, 0.0005, 0.0005, 0.0002, 0.0003, 0.0005, 0.0003, 0.0002, 0.0008, 0.0015, 0.0004, 0.0003, 0.0001, 0.0002, 0.0003, 0.0007, 0.0003, 0.0024, 0.0006, 0.0003, 0.0002, 0.0006, 0.0005, 0.0001, 0.0006, 0.0003, 0.0007, 0.0004, 0.0002, 0.0005, 0.0001, 0.0001, 0.0006, 0.0002, 0.0002, 0.0003, 0.0, 0.0005, 0.0002, 0.0004, 0.0003, 0.0001, 0.0, 0.0002, 0.0002, 0.0, 0.0001, 0.0004, 0.0005, 0.0005, 0.0003, 0.0007, 0.0002, 0.0005, 0.0009, 0.0004, 0.0007, 0.0006, 0.0001, 0.0002, 0.0001, 0.0002, 0.0003, 0.0, 0.0002, 0.001, 0.0004, 0.0002, 0.0001, 0.0005, 0.0003, 0.0002, 0.0005, 0.0002, 0.0004, 0.001, 0.0001, 0.0004, 0.0003, 0.001, 0.0006, 0.0003, 0.0005, 0.0, 0.0002, 0.0004, 0.0002, 0.0001, 0.0004, 0.0005, 0.0003, 0.0004, 0.0003, 0.0004, 0.0007, 0.0002, 0.0003, 0.0003, 0.0001, 0.0003, 0.0005, 0.0007, 0.0003, 0.0001, 0.0006, 0.0006, 0.0004, 0.0003, 0.0002, 0.0001, 0.0005, 0.0005, 0.0003, 0.0001, 0.0001, 0.0005, 0.0, 0.0003, 0.0004, 0.0001, 0.0004, 0.0006, 0.0003, 0.0001, 0.0002, 0.0005, 0.0001, 0.0002, 0.0003, 0.0003, 0.0008, 0.0004, 0.0002, 0.0001, 0.0007, 0.0003, 0.0003, 0.0002, 0.0006, 0.0002, 0.0004, 0.0003, 0.0003, 0.0, 0.0005, 0.0001, 0.0, 0.0005, 0.0002, 0.0009, 0.0004, 0.0003, 0.0002, 0.0006, 0.0003, 0.0004, 0.0002, 0.0004, 0.0001, 0.0002, 0.0001, 0.0003, 0.0, 0.0006, 0.0003, 0.0004, 0.0004, 0.0008, 0.0001, 0.0003, 0.0007, 0.0003, 0.0001, 0.0005, 0.0007, 0.0002, 0.0001, 0.0004, 0.0001, 0.0001, 0.0004, 0.0003, 0.0002, 0.0004, 0.0005, 0.0006, 0.0002, 0.0006, 0.0003, 0.0004, 0.0004, 0.0006, 0.0001, 0.0001, 0.0008, 0.0004, 0.0003, 0.0004, 0.0002, 0.0003, 0.0003, 0.0004, 0.0003, 0.0008, 0.0002, 0.0, 0.0, 0.0004, 0.0004, 0.0002, 0.0002, 0.0002, 0.0001, 0.0002, 0.0003, 0.0001, 0.0006, 0.0002, 0.0003, 0.0001, 0.0004, 0.0002, 0.0003, 0.0005, 0.0004, 0.0002, 0.0001, 0.0001, 0.0006, 0.0003, 0.0001, 0.0005, 0.0002, 0.0002, 0.0004, 0.0001, 0.0001, 0.0001, 0.0007, 0.0003, 0.0003, 0.0003, 0.0003, 0.0001, 0.0003, 0.0007, 0.0001, 0.0001, 0.0003, 0.0009, 0.0002, 0.0001, 0.0005, 0.0001, 0.0001, 0.0001, 0.0001, 0.0002, 0.0002, 0.0001, 0.0002, 0.0001, 0.0001, 0.0001, 0.0006, 0.0002, 0.0003, 0.0002, 0.0002, 0.0, 0.0, 0.0002, 0.0003, 0.0001, 0.0002, 0.0002, 0.0002, 0.0, 0.0001, 0.0002, 0.0001, 0.0002, 0.0001, 0.0, 0.0002, 0.0003, 0.0003, 0.0008, 0.0001, 0.0002, 0.0002, 0.0002, 0.0003, 0.0002, 0.0001, 0.0002, 0.0006, 0.0004, 0.0002, 0.0, 0.0004, 0.0002, 0.0, 0.0, 0.0002, 0.0002, 0.0001, 0.0003, 0.0001, 0.0002, 0.0003, 0.0002, 0.0003, 0.0001, 0.0003, 0.0002, 0.0, 0.0003, 0.0001, 0.0006, 0.0001, 0.0002, 0.0002, 0.0005, 0.0001, 0.0001, 0.0003, 0.0001, 0.0, 0.0005, 0.0007, 0.0002, 0.0001, 0.0001, 0.0005, 0.0, 0.0001, 0.0003, 0.0001, 0.001, 0.0002, 0.0002, 0.0005, 0.0003, 0.0, 0.0002, 0.0001, 0.0001, 0.0002, 0.0002, 0.0, 0.0002, 0.0006, 0.0001, 0.0002, 0.0001, 0.0004, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0002, 0.0003, 0.0002, 0.0005, 0.0003, 0.0006, 0.0002, 0.0, 0.0, 0.0003, 0.0, 0.0007, 0.0004, 0.0001, 0.0002, 0.0002, 0.0001, 0.0002, 0.0001, 0.0001, 0.0, 0.0005, 0.0001, 0.0001, 0.0003, 0.0001, 0.0004, 0.0002, 0.0002, 0.0005, 0.0003, 0.0001, 0.0002, 0.0001, 0.0004, 0.0001, 0.0005, 0.0001, 0.0005, 0.0001, 0.0001, 0.0001, 0.0001, 0.0003, 0.0005, 0.0003, 0.0001, 0.0004, 0.0001, 0.0002, 0.0002, 0.0001, 0.0004, 0.0006, 0.0, 0.0001, 0.0005, 0.0001, 0.0003, 0.0001, 0.0002, 0.0004, 0.0011, 0.0001, 0.0004, 0.0007, 0.0001, 0.0003, 0.0001, 0.0002, 0.0, 0.0001, 0.0, 0.0005, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0, 0.0005, 0.0004, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0003, 0.0001, 0.0003, 0.0003, 0.0003, 0.0004, 0.0004, 0.0002, 0.0003, 0.0001, 0.0001, 0.0, 0.0, 0.0003, 0.0005, 0.0002, 0.0004, 0.0007, 0.0002, 0.0, 0.0004, 0.0001, 0.0, 0.0003, 0.0001, 0.0, 0.0002, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0004, 0.0002, 0.0004, 0.0002, 0.0002, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0005, 0.0001, 0.0001, 0.0002, 0.0003, 0.0, 0.0001, 0.0006, 0.0005, 0.0, 0.0001, 0.0003, 0.0001, 0.0003, 0.0004, 0.0, 0.0006, 0.0001, 0.0004, 0.0001, 0.0001, 0.0002, 0.0001, 0.0002, 0.0003, 0.0001, 0.0002, 0.0, 0.0, 0.0001, 0.0002, 0.0004, 0.0003, 0.0002, 0.0003, 0.0003, 0.0002, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0003, 0.0001, 0.0002, 0.0001, 0.0003, 0.0001, 0.0002, 0.0003, 0.0003, 0.0, 0.0003, 0.0005, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0002, 0.0006, 0.0001, 0.0002, 0.0001, 0.0003, 0.0, 0.0001, 0.0001, 0.0002, 0.0001, 0.0, 0.0005, 0.0001, 0.0005, 0.0003, 0.0003, 0.0005, 0.0001, 0.0001, 0.0003, 0.0003, 0.0005, 0.0001, 0.0004, 0.0002, 0.0001, 0.0002, 0.0001, 0.0005, 0.0, 0.0002, 0.0002, 0.0004, 0.0, 0.0003, 0.0, 0.0005, 0.0002, 0.0001, 0.0001, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0003, 0.0001, 0.0002, 0.0, 0.0002, 0.0, 0.0003, 0.0, 0.0, 0.0002, 0.0003, 0.0005, 0.0, 0.0001, 0.0001, 0.0004, 0.0002, 0.0003, 0.0002, 0.0004, 0.0003, 0.0, 0.0006, 0.0002, 0.0, 0.0002, 0.0005, 0.0, 0.0011, 0.0002, 0.0005, 0.0, 0.0001, 0.0, 0.0001, 0.001, 0.0001, 0.0002, 0.0001, 0.0003, 0.0001, 0.0005, 0.0001, 0.0006, 0.0006, 0.0004, 0.0001, 0.0001, 0.0002, 0.0002, 0.0, 0.0001, 0.0004, 0.0002, 0.0003, 0.0, 0.0001, 0.0001, 0.0003, 0.0006, 0.0005, 0.0004, 0.0, 0.0002, 0.0003, 0.0002, 0.0, 0.0007, 0.0001, 0.0001, 0.0002, 0.0002, 0.0002, 0.0005, 0.0002, 0.0002, 0.0003, 0.0001, 0.0001, 0.0001, 0.0002, 0.0, 0.0003, 0.0003, 0.0, 0.0006, 0.0002, 0.0001, 0.0, 0.0003, 0.0002, 0.0002, 0.0001, 0.0004, 0.0005, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0003, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0004, 0.0003, 0.0, 0.0003, 0.0002, 0.0, 0.0003, 0.0001, 0.0001, 0.0006, 0.0001, 0.0003, 0.0002, 0.0001, 0.0004, 0.0002, 0.0001, 0.0001, 0.0001, 0.0003, 0.0003, 0.0001, 0.0001, 0.0002, 0.0002, 0.0001, 0.0001, 0.0003, 0.0005, 0.0002, 0.0, 0.0002, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0003, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0003, 0.0, 0.0001, 0.0001, 0.0, 0.0003, 0.0002, 0.0004, 0.0003, 0.0, 0.0, 0.0008, 0.0003, 0.0, 0.0001, 0.0001, 0.0002, 0.0001, 0.0002, 0.0001, 0.0003, 0.0002, 0.0004, 0.0004, 0.0002, 0.0002, 0.0, 0.0, 0.0001, 0.0003, 0.0002, 0.0001, 0.0001, 0.0008, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0002, 0.0003, 0.0001, 0.0001, 0.0001, 0.0002, 0.0004, 0.0, 0.0002, 0.0001, 0.0002, 0.0001, 0.0001, 0.0, 0.0002, 0.0003, 0.0007, 0.0001, 0.0001, 0.0006, 0.0001, 0.0001, 0.0002, 0.0001, 0.0002, 0.0, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0003, 0.0002, 0.0001, 0.0002, 0.0002, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0002, 0.0001, 0.0, 0.0002, 0.0, 0.0005, 0.0001, 0.0001, 0.0001, 0.0004, 0.0001, 0.0, 0.0003, 0.0002, 0.0001, 0.0001, 0.0006, 0.0002, 0.0, 0.0, 0.0003, 0.0003, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0003, 0.0001, 0.0003, 0.0003, 0.0002, 0.0, 0.0001, 0.0002, 0.0, 0.0001, 0.0001, 0.0, 0.0002, 0.0002, 0.0, 0.0, 0.0, 0.0004, 0.0001, 0.0001, 0.0, 0.0003, 0.0001, 0.0, 0.0001, 0.0001, 0.0001, 0.0001, 0.0002, 0.0001, 0.0001, 0.0, 0.0002, 0.0004, 0.0003, 0.0007, 0.0003, 0.0, 0.0001, 0.0002, 0.0001, 0.0004, 0.0001, 0.0001, 0.0, 0.0001, 0.0002, 0.0001, 0.0002, 0.0001, 0.0, 0.0002, 0.0001, 0.0006, 0.0001, 0.0, 0.0002, 0.0001, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0002, 0.0001, 0.0002, 0.0001, 0.0, 0.0002, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0002, 0.0001, 0.0001, 0.0, 0.0003, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0001, 0.0006, 0.0001, 0.0003, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0008, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0001, 0.0002, 0.0, 0.0, 0.0002, 0.0001, 0.0003, 0.0002, 0.0001, 0.0001, 0.0, 0.0001, 0.0004, 0.0001, 0.0002, 0.0004, 0.0003, 0.0, 0.0002, 0.0002, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0003, 0.0001, 0.0001, 0.0005, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0002, 0.0002, 0.0001, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0002, 0.0003, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0003, 0.0002, 0.0003, 0.0001, 0.0001, 0.0001, 0.0001, 0.0004, 0.0001, 0.0001, 0.0001, 0.0006, 0.0007, 0.0, 0.0003, 0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001, 0.0002, 0.0, 0.0008, 0.0001, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0004, 0.0003, 0.0001, 0.0004, 0.0, 0.0, 0.0003, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0, 0.0005, 0.0002, 0.0002, 0.0, 0.0001, 0.0004, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0002, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0002, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0002, 0.0001, 0.0004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0003, 0.0002, 0.0002, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0001, 0.0002, 0.0, 0.0002, 0.0001, 0.0005, 0.0002, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0003, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0004, 0.0001, 0.0001, 0.0, 0.0001, 0.0002, 0.0, 0.0003, 0.0001, 0.0, 0.0005, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0002, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0001, 0.0003, 0.0, 0.0001, 0.0003, 0.0001, 0.0003, 0.0, 0.0, 0.0002, 0.0, 0.0004, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0001, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0001, 0.0004, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0003, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0001, 0.0001, 0.0, 0.0001, 0.0001, 0.0002, 0.0001, 0.0001, 0.0, 0.0003, 0.0002, 0.0001, 0.0, 0.0001, 0.0001, 0.0001, 0.0003, 0.0003, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0003, 0.0001, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0002, 0.0002, 0.0, 0.0001, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0002, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0003, 0.0001, 0.0, 0.0004, 0.0, 0.0, 0.0, 0.0002, 0.0006, 0.0001, 0.0, 0.0, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0007, 0.0001, 0.0003, 0.0001, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0002, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0007, 0.0002, 0.0, 0.0003, 0.0001, 0.0002, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0, 0.0002, 0.0001, 0.0001, 0.0001, 0.0004, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0008, 0.0005, 0.0, 0.0002, 0.0001, 0.0, 0.0004, 0.0, 0.0004, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0005, 0.0002, 0.0002, 0.0001, 0.0, 0.0001, 0.0003, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0002, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0004, 0.0004, 0.0, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0003, 0.0, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0001, 0.0003, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0002, 0.0002, 0.0002, 0.0001, 0.0, 0.0003, 0.0002, 0.0002, 0.0001, 0.0001, 0.0, 0.0001, 0.0004, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0, 0.0001, 0.0001, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0002, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0, 0.0001, 0.0001, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0006, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0002, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0004, 0.0, 0.0001, 0.0006, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0005, 0.0002, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0001, 0.0, 0.0, 0.0004, 0.0001, 0.0001, 0.0004, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0002, 0.0, 0.0, 0.0003, 0.0, 0.0002, 0.0002, 0.0004, 0.0001, 0.0001, 0.0001, 0.0003, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0004, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0004, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0004, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0003, 0.0001, 0.0, 0.0002, 0.0001, 0.0002, 0.0, 0.0, 0.0001, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0002, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0005, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0003, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0006, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0001, 0.0, 0.0001, 0.0002, 0.0002, 0.0001, 0.0, 0.0002, 0.0001, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0003, 0.0001, 0.0001, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0003, 0.0003, 0.0, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0.0005, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0002, 0.0002, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0002, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0004, 0.0001, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0004, 0.0, 0.0, 0.0002, 0.0002, 0.0, 0.0001, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0002, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0002, 0.0001, 0.0, 0.0003, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0002, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0004, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0002, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0002, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0004, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0002, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0002, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0002, 0.0, 0.0004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0004, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0003, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0002, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0004, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0003, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0004, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0004, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0004, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0003, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0, 0.0, 0.0, 0.0003, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0]), prediction=99.0)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9719813914146754\n",
      "0.995637881327191\n"
     ]
    }
   ],
   "source": [
    "evaluator = ev.BinaryClassificationEvaluator(\n",
    "    rawPredictionCol='probability', \n",
    "    labelCol='Num_Suicides_100k_indexer')\n",
    "\n",
    "print(evaluator.evaluate(test, \n",
    "     {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(test, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claramente aqui hemos hecho overfitting ya que estamos muy cerca del 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper_Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.tuning as tune\n",
    "import pyspark.ml.evaluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cl.RandomForestClassifier(numTrees=5, maxDepth=5, labelCol='Num_Suicides_100k_indexer')\n",
    "\n",
    "grid = tune.ParamGridBuilder().addGrid(classifier.numTrees, [4, 6]).addGrid(classifier.maxDepth, [3,7]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ev.BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='Num_Suicides_100k_indexer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = tune.CrossValidator(estimator=classifier, estimatorParamMaps=grid, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[indexer,featuresCreator])\n",
    "data_transformer = pipeline.fit(suicides_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(data_transformer.transform(suicides_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "data_train = data_transformer.transform(suicides_test)\n",
    "results = cvModel.transform(data_train)\n",
    "\n",
    "print(evaluator.evaluate(results, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(results, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-cee3aadfd30e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     in zip(\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mcvModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEstimatorParamMaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcvModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgMetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cvModel' is not defined"
     ]
    }
   ],
   "source": [
    "results = [\n",
    "    (\n",
    "        [\n",
    "            {key.name: paramValue} \n",
    "            for key, paramValue \n",
    "            in zip(\n",
    "                params.keys(), \n",
    "                params.values())\n",
    "        ], metric\n",
    "    ) \n",
    "    for params, metric \n",
    "    in zip(\n",
    "        cvModel.getEstimatorParamMaps(), \n",
    "        cvModel.avgMetrics\n",
    "    )\n",
    "]\n",
    "\n",
    "sorted(results, key=lambda el: el[1], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
